{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #3 Part 2: Image Captioning with RNNs\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Sunyoung Kwon, September 2017\n",
    "\n",
    "Now, you're going to leave behind your implementations and instead migrate to one of popular deep learning frameworks, **TensorFlow**. <br>\n",
    "In this notebook, <font color=red>**you should use tensorflow RNN libraries**</font> for image captioning of the Microsoft COCO dataset. <br>\n",
    "\n",
    "For this exercise we will use the 2014 release of the **[Microsoft COCO dataset](http://mscoco.org/)** which has become the standard testbed for image captioning. The dataset consists of about 80,000 images, each annotated with 5 captions written by workers on Amazon Mechanical Turk.\n",
    "\n",
    "The raw images takes up so much (nearly 20GB), we will use the preprocessed COCO datasets which are extracted features from the VGG-16 network and reduced the dimensionality of the features from 4096 to 512 by standford CS231N lecture.\n",
    "\n",
    "To download the data, change to the `coco/` directory and run the script `get_coco_data.sh`.\n",
    "- caption and image index: `train2014_captions.h5`\n",
    "- idx_to_word, word_to_idx: `coco2014_vocab.json`\n",
    "- extracted and reduced image features: `train2014_vgg16_fc7_pca.h5`\n",
    "- URLs of the images for visualization: `train2014_urls.txt`\n",
    "  <br>(Since images are downloaded on-the-fly, **you must be connected to the internet to view images**)\n",
    "\n",
    "The file `coco_utils.py` has utilities for coco datasets from load COCO data to visualization and evaluation.\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all Assignment Part 1, 2 & 3**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* team_#)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #3:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Microsoft COCO (http://mscoco.org/dataset/#overview)\n",
    "- [4] Microsoft COCO Captions (https://arxiv.org/pdf/1504.00325.pdf)\n",
    "- [5] Vinyals, Oriol, et al. \"Show and tell: Lessons learned from the 2015 mscoco image captioning challenge.\" IEEE transactions on pattern analysis and machine intelligence 39.4 (2017): 652-663.\n",
    "\n",
    "\n",
    "\n",
    "## Image Captioning (40 points)\n",
    "\n",
    "- input : extracted image features from the VGG-16 network<br>\n",
    "- output: predicted captions<br>\n",
    "- evaluation: average BLEU scores for validation and independent test dataset\n",
    "- data: download by run the `./coco/get_coco_data.sh`\n",
    "- model: save your captiong model in model_path (`./models_captioning`)\n",
    "- You muse use TensorFlow RNN module (such as tf.contrib.rnn)\n",
    "\n",
    "Example of image captioning \n",
    "\n",
    "<img src=\"./files/showandtell.png\" width=70%>\n",
    "[Source: \"Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "The preprocessed COCO datasets and libraries are loaded.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "from coco_utils import *\n",
    "from captioning import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "model_path='./models_captioning'\n",
    "data_path ='./coco/coco_captioning'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data load complete\n",
      "train_captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "train_image_idxs <class 'numpy.ndarray'> (400135,) int32\n",
      "features <class 'numpy.ndarray'> (82783, 512) float32\n",
      "idx_to_word <class 'list'> 1004\n",
      "word_to_idx <class 'dict'> 1004\n",
      "urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "val_captions <class 'numpy.ndarray'> (10000, 17) int32\n",
      "val_image_idxs <class 'numpy.ndarray'> (10000,) int32\n"
     ]
    }
   ],
   "source": [
    "# Load COCO data from disk; this returns a dictionary\n",
    "# We'll work with dimensionality-reduced features for this notebook\n",
    "    \n",
    "data = load_coco_data(base_dir=data_path)\n",
    "if len(data)==8 : \n",
    "    print('COCO data load complete')\n",
    "   \n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions for data\n",
    "- data['train_captions'] : 400135장의 중복사진에 대한 캡션(최대 17글자로 각 글자는 1024개 단어 사전 중 하나)\n",
    "- data['train_image_idxs'] : 400135장의 중복사진은 82783 종류로 분류되며 각 사진이 어떤 종류인지 0~82782의 idx로 대응\n",
    "- data['features'] : 82783 종류에 대해 VGG-16 network를 통해 얻은 feature로 크기는 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   4 142 510  10 667 415 277  58   2   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(data['train_captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'C:\\\\Users\\\\Owner\\\\AppData\\\\Local\\\\Temp\\\\tmpimejvxvo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-31ed0d984188>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sample images and captions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_coco_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mshow_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\과제\\Assignment3.tar\\coco_utils.py\u001b[0m in \u001b[0;36mshow_samples\u001b[1;34m(captions, urls, data)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcaption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_from_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mcaption_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_captions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx_to_word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\과제\\Assignment3.tar\\coco_utils.py\u001b[0m in \u001b[0;36mimage_from_url\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    103\u001b[0m       \u001b[0mff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'C:\\\\Users\\\\Owner\\\\AppData\\\\Local\\\\Temp\\\\tmpimejvxvo'"
     ]
    }
   ],
   "source": [
    "# Sample images and captions\n",
    "captions, features, urls = sample_coco_minibatch(data, batch_size=1)\n",
    "show_samples(captions, urls, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for training\n",
    "\n",
    "For simple test, you can load subsample of total train data.<br>\n",
    "But you should use <font color=red>**full train_data**</font> for final test.<br>\n",
    "You will be able to verify your captioning model more quickly with the small train data.<br>\n",
    "<font color=red>**You must show loss changes with full train data**</font> when you train. <br>\n",
    "And you must show maxlen, n_words, captions.shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n",
      "17\n",
      "(500, 512) (500, 17)\n",
      "(10000, 512) (10000, 17)\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# CAUTION: Do not change maxlen(17), n_words(1004), input_dimension(512)\n",
    "# you should use 512 extracted image features\n",
    "# Do not change coco_utils.py\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------\n",
    "# [case 1] subsample\n",
    "# Try to subsamples of train_data for simple test\n",
    "#----------------------------------------------\n",
    "train_data = load_coco_data(base_dir=data_path, max_train=500)\n",
    "\n",
    "#----------------------------------------------\n",
    "# [case 2] full train data\n",
    "# Try to full train_data for real test\n",
    "#----------------------------------------------\n",
    "#train_data = data\n",
    "\n",
    "captions = train_data['train_captions']\n",
    "img_idx  = train_data['train_image_idxs']\n",
    "img_features = train_data['features'][img_idx] # match imgs - features / shape (400135, 512)\n",
    "word_to_idx = train_data['word_to_idx']\n",
    "idx_to_word = train_data['idx_to_word']\n",
    "\n",
    "n_words = len(word_to_idx)\n",
    "maxlen = train_data['train_captions'].shape[1]\n",
    "input_dimension = train_data['features'].shape[1]\n",
    "\n",
    "\n",
    "print(n_words)\n",
    "print(maxlen)\n",
    "print(img_features.shape, captions.shape)\n",
    "\n",
    "vcaptions = train_data['val_captions']\n",
    "vimg_idx  = train_data['val_image_idxs']\n",
    "vimg_features = train_data['features'][vimg_idx]\n",
    "print(vimg_features.shape, vcaptions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', 'a', 'zebra', 'standing', 'in', 'a', 'green', 'grass', 'covered', 'field', 'next', 'to', 'trees', '<END>', '<NULL>', '<NULL>', '<NULL>']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "#print(idx_to_word[data['train_captions'][0]])\n",
    "print([idx_to_word[i] for i in captions[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of captioning failed: Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\과제\\Assignment3.tar\\captioning.py\", line 44\n",
      "    @lazy_property\n",
      "                 ^\n",
      "IndentationError: unindent does not match any outer indentation level\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# TODO: Implement for caption training class in captioning.py\n",
    "# you should use TensorFlow RNN libraries (such as tf.contrib.rnn)\n",
    "# You can modify classes, functions, parameters according to your model structure.\n",
    "# You can also hide the train function in the Captioning class.\n",
    "# Just show the loss changes depending on the learning procedure.\n",
    "#\n",
    "# class Captioning():\n",
    "#     def __init(self,...):\n",
    "#     def model(self,...):\n",
    "#     def predict(self,...):\n",
    "#################################################################################\n",
    "\"\"\"\n",
    "def train(img_features, captions):\n",
    "    #-------------------------------------------------------------\n",
    "    # You must show maxlen, n_words, caption.shape !!\n",
    "    #-------------------------------------------------------------\n",
    "    print(maxlen, n_words, captions.shape)\n",
    "    #################################################\n",
    "    # TODO: Implement caption training\n",
    "    # - save your trained model in model_path\n",
    "    # - must print about 10 loss changes !!\n",
    "    #################################################\n",
    "\n",
    "    \n",
    "    #print(\"Current Cost: \", loss_value, \"\\t Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    \n",
    "    #################################################\n",
    "    #                END OF YOUR CODE               #\n",
    "    #################################################\n",
    "    \n",
    "train(img_features, captions) \n",
    "\"\"\"\n",
    "\n",
    "from captioning import *\n",
    "model = Captioning(batch_size =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss : 6.570   accuracy : 22.289\n",
      "iter: 1   loss : 6.378   accuracy : 30.607\n",
      "iter: 2   loss : 6.271   accuracy : 31.388\n",
      "iter: 3   loss : 6.209   accuracy : 32.583\n",
      "iter: 4   loss : 6.161   accuracy : 33.594\n",
      "iter: 5   loss : 6.119   accuracy : 34.651\n",
      "iter: 6   loss : 6.079   accuracy : 35.892\n",
      "iter: 7   loss : 6.041   accuracy : 36.581\n",
      "iter: 8   loss : 6.002   accuracy : 37.224\n",
      "iter: 9   loss : 5.962   accuracy : 37.178\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "hidden_size = 512\n",
    "timesteps = 17\n",
    "n_words = 1004\n",
    "batch_size = 100\n",
    "\n",
    "h0 = tf.placeholder(tf.float32, shape = [batch_size, hidden_size])\n",
    "labels = tf.placeholder(tf.float32, [batch_size, timesteps, n_words])\n",
    "\n",
    "\n",
    "\n",
    "lstm = tf.contrib.rnn.LSTMBlockCell(hidden_size)\n",
    "\n",
    "#we should add [0,0...,0] to first input\n",
    "x0 = tf.zeros([batch_size, 1, n_words])\n",
    "_input = tf.concat([x0,labels[:,:timesteps-1,:]], axis = 1)\n",
    "#_input = labels\n",
    "state = lstm.zero_state(batch_size, tf.float32)\n",
    "\"\"\"\n",
    "state = [h0]\n",
    "for i in range(timesteps-1):\n",
    "    state.append(tf.Variable(tf.zeros([batch_size, hidden_size])))\n",
    "    \n",
    "state = tuple(state)\n",
    "\"\"\"\n",
    "\n",
    "c_init = np.zeros((batch_size, lstm.state_size.c), np.float32)\n",
    "#h_init = np.zeros((batch_size, lstm.state_size.h), np.float32)\n",
    "h_init = h0\n",
    "\n",
    "state_init = [c_init, h_init]\n",
    "\n",
    "\"\"\"\n",
    "c_in = tf.placeholder(tf.float32, \n",
    "            shape=[batch_size, lstm.state_size.c],\n",
    "            name='c_in')\n",
    "h_in = tf.placeholder(tf.float32, \n",
    "            shape=[batch_size, lstm.state_size.h],\n",
    "            name='h_in')\n",
    "state_in = [c_in, h_in]\n",
    "\"\"\"\n",
    "state_in = rnn.LSTMStateTuple(c_init, h_init)\n",
    "#_input = tf.unstack(labels, timesteps, axis=1)\n",
    "#print(_input[0])\n",
    "\n",
    "#outputs = []\n",
    "#for t in range(timesteps):\n",
    "hidden_output, _= tf.nn.dynamic_rnn(lstm, _input, initial_state = state_in, time_major = False, dtype = tf.float32)\n",
    "    #outputs.append(output)\n",
    "    \n",
    "Wy = tf.Variable(tf.truncated_normal([hidden_size, n_words])) # hidden state : (batch_size, hidden_len=512) / y : (batch_size, n_word = 1004)\n",
    "by = tf.Variable(tf.zeros([n_words]), dtype = tf.float32)    \n",
    "\n",
    "hidden_output = tf.unstack(hidden_output, timesteps, axis = 1)\n",
    "labels_us = tf.unstack(labels, timesteps, axis=1)\n",
    "\n",
    "losses = 0\n",
    "accuracy = 0\n",
    "outputs = []\n",
    "for i in range(timesteps):\n",
    "    output = tf.matmul(hidden_output[i], Wy) + by\n",
    "    output = tf.nn.tanh(output)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = output, labels = labels_us[i]))\n",
    "    losses += loss\n",
    "    outputs.append(output)\n",
    "    #accuracy += tf.reduce_sum(tf.math.equal(tf.argmax(output,axis=1), tf.argmax(labels_us[i], axis = 1)))\n",
    "losses /= timesteps\n",
    "accuracy /= timesteps\n",
    "\n",
    "optimize = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(losses)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#captions : (5,17) -> (5, 17, 1004)\n",
    "cap =  (np.arange(n_words) == captions[:,:,None]).astype(np.float32)\n",
    "\n",
    "num_iterations = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    permutation = np.random.permutation(img_features.shape[0])\n",
    "    shuffled_h0 = img_features[permutation,:]\n",
    "    shuffled_captions = cap[permutation,:]\n",
    "    for iter in range(num_iterations):\n",
    "        offset = iter * batch_size % (img_features.shape[0] - batch_size)\n",
    "        batch_h0 = shuffled_h0[offset:offset+batch_size]\n",
    "        batch_captions =  shuffled_captions[offset:offset+batch_size]\n",
    "        feeds = {h0 : batch_h0, labels : batch_captions}\n",
    "                \n",
    "        sess.run(optimize, feed_dict = feeds)\n",
    "        loss = sess.run(losses, feed_dict = feeds)\n",
    "        \n",
    "        out, lab = sess.run([outputs, labels_us], feed_dict = feeds)\n",
    "        acc = 0\n",
    "        for i in range(timesteps):\n",
    "            acc += np.sum(np.equal(np.argmax(out[i],axis=1), np.argmax(lab[i],axis=1))) / batch_size\n",
    "        acc /= timesteps\n",
    "        print(\"iter: %d   loss : %.3f   accuracy : %.3f\" % (iter, loss, acc * 100))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0   loss : 6.593   accuracy : 17.325\n",
      "iter: 1   loss : 6.555   accuracy : 27.895\n",
      "iter: 2   loss : 6.528   accuracy : 28.447\n",
      "iter: 3   loss : 6.303   accuracy : 33.732\n",
      "iter: 4   loss : 6.323   accuracy : 32.767\n",
      "iter: 5   loss : 6.316   accuracy : 31.388\n",
      "iter: 6   loss : 6.187   accuracy : 38.465\n",
      "iter: 7   loss : 6.187   accuracy : 36.811\n",
      "iter: 8   loss : 6.192   accuracy : 33.824\n",
      "iter: 9   loss : 6.092   accuracy : 34.697\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "from captioning import *\n",
    "\n",
    "hidden_size = 512\n",
    "timesteps = 17\n",
    "n_words = 1004\n",
    "batch_size = 128\n",
    "LSTM_model = Captioning(batch_size = batch_size)\n",
    "\n",
    "#captions : (5,17) -> (5, 17, 1004)\n",
    "cap =  (np.arange(n_words) == captions[:,:,None]).astype(np.float32)\n",
    "\n",
    "num_iterations = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    permutation = np.random.permutation(img_features.shape[0])\n",
    "    shuffled_h0 = img_features[permutation,:]\n",
    "    shuffled_captions = cap[permutation,:]\n",
    "    for step in range(num_iterations):\n",
    "        offset = step * batch_size % (img_features.shape[0] - batch_size)\n",
    "        batch_h0 = shuffled_h0[offset:offset+batch_size]\n",
    "        batch_captions =  shuffled_captions[offset:offset+batch_size]\n",
    "        feeds = {LSTM_model.h0 : batch_h0, LSTM_model.labels : batch_captions}\n",
    "                \n",
    "        sess.run(LSTM_model.train, feed_dict = feeds)\n",
    "        loss = sess.run(LSTM_model.loss, feed_dict = feeds)\n",
    "        \n",
    "        out, lab = sess.run([LSTM_model.outputs, LSTM_model.labels_unstack], feed_dict = feeds)\n",
    "        acc = 0\n",
    "        for i in range(timesteps):\n",
    "            acc += np.sum(np.equal(np.argmax(out[i],axis=1), np.argmax(lab[i],axis=1))) / batch_size\n",
    "        acc /= timesteps\n",
    "        print(\"iter: %d\\n    train loss : %.3f   train accuracy : %.3f\" % (iter, loss, acc * 100))\n",
    "        print(\"    valid loss : %.3f    valid accuracy : %.3f\" % )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "def run_model(session, model, X, Y, epochs=1, batch_size = 128, is_training=False):\n",
    "    #for training\n",
    "    iterations = math.ceil(Y.shape[0] // batch_size)\n",
    "    if is_training:\n",
    "        for epoch in range(epochs):\n",
    "            # data randomization (shuffle)\n",
    "            permutation = np.random.permutation(Y.shape[0])\n",
    "            shuffled_dataset = X[permutation,:]\n",
    "            shuffled_labels = Y[permutation,:]\n",
    "            time_sum = 0\n",
    "            n_time = 0\n",
    "            for step in range(iterations):\n",
    "                offset = step * batch_size % (Y.shape[0] - batch_size)\n",
    "                batch_x = shuffled_dataset[offset:offset+batch_size]\n",
    "                batch_y = shuffled_labels[offset:offset+batch_size]\n",
    "                batch_y = captions_encoding(batch_y)\n",
    "                \n",
    "                feeds = {model.h0 : batch_x, model.labels : batch_y, model.keep_probs : 0.5}\n",
    "                start_train = time.time()\n",
    "                session.run(model.optimize, feed_dict = feeds)\n",
    "                time_sum += (time.time() - start_train)\n",
    "                n_time += 1\n",
    "                \n",
    "                if(step % 100 == 0):\n",
    "                    start_loss = time.time()\n",
    "                    #calculate loss\n",
    "                    los = session.run(model.loss, feed_dict = feeds)\n",
    "                    #calculate accuracy\n",
    "                    acc = 0\n",
    "                    out, lab = session.run([model.outputs, model.labels_unstack], feed_dict = feeds)\n",
    "                    for i in range(timesteps):\n",
    "                        acc += np.sum(np.equal(np.argmax(out[i],axis=1), np.argmax(lab[i],axis=1))) / batch_size\n",
    "                    acc /= timesteps\n",
    "                    #add to draw a performance curve\n",
    "                    train_loss.append(los) # loss per batch_size\n",
    "                    train_acc.append(acc * 100)\n",
    "                    #print how much time has passed\n",
    "                    print(\"epoch %d (iter %d/%d)\\n   train_time: %.3f  loss_time: %.3f\" \n",
    "                          % (epoch+1, step, iterations, time_sum/n_time, time.time() - start_loss))\n",
    "                    time_sum = 0\n",
    "                    n_time = 0\n",
    "                    #print train acc / loss\n",
    "                    print(\"   train accuracy %.2f%%  train loss %.3f\" \n",
    "                          % (acc * 100, los))\n",
    "                \"\"\"\n",
    "                t_valid = time.time()\n",
    "                los, acc = run_model(session, model, X_val, Y_val)\n",
    "                valid_loss.append(los)\n",
    "                valid_acc.append(acc)\n",
    "                print(\"   valid time: %.3f\" % (time.time() - t_valid))\n",
    "                print(\"   valid accuracy %.2f%%  valid loss %.3f\" % (acc, los * batch_size))\n",
    "                \"\"\"\n",
    "        print(\"Training done!\")\n",
    "    else:\n",
    "        ls = 0\n",
    "        acc = 0\n",
    "        for step in range(iterations):\n",
    "            offset = step * batch_size % (Y.shape[0] - batch_size)\n",
    "            batch_x = X[offset:offset+batch_size]\n",
    "            batch_y = Y[offset:offset+batch_size]\n",
    "            batch_y = captions_encoding(batch_y)\n",
    "            feeds = {model.h0 : batch_x, model.labels : batch_y, model.keep_probs : 0.5}\n",
    "            #calculate loss\n",
    "            l = session.run(model.loss, feed_dict = feeds)\n",
    "            #calculate accuracy\n",
    "            acc = 0\n",
    "            out, lab = session.run([model.outputs, model.labels_unstack], feed_dict = feeds)\n",
    "            for i in range(timesteps):\n",
    "                acc += np.sum(np.equal(np.argmax(out[i],axis=1), np.argmax(lab[i],axis=1))) / batch_size\n",
    "            acc /= timesteps            \n",
    "            ls += l\n",
    "        return (ls / X.shape[0], acc / X.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400135, 512) (400135, 17)\n",
      "(10000, 512) (10000, 17)\n"
     ]
    }
   ],
   "source": [
    "Y_train = data['train_captions']\n",
    "img_idx = data['train_image_idxs']\n",
    "X_train = data['features'][img_idx]\n",
    "\n",
    "Y_val = data['val_captions']\n",
    "val_img_idx = data['val_image_idxs']\n",
    "X_val = data['features'][val_img_idx]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "\n",
    "#captions : (5,17) -> (5, 17, 1004)\n",
    "def captions_encoding(captions) :\n",
    "    return (np.arange(n_words) == captions[:,:,None]).astype(np.float32)\n",
    "\n",
    "#Y_train_e = captions_encoding(Y_train)\n",
    "#Y_val_e = captions_encoding(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LSTM Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Construct Start\n",
      "Model Construct Finished || time consumed : 3.130\n",
      "Train Start\n",
      "epoch 1 (iter 0/3126)\n",
      "   train_time: 2.264  loss_time: 1.285\n",
      "   train accuracy 0.13%  train loss 6.606\n",
      "epoch 1 (iter 100/3126)\n",
      "   train_time: 1.417  loss_time: 1.018\n",
      "   train accuracy 0.24%  train loss 5.581\n",
      "epoch 1 (iter 200/3126)\n",
      "   train_time: 1.409  loss_time: 1.017\n",
      "   train accuracy 0.24%  train loss 5.445\n",
      "epoch 1 (iter 300/3126)\n",
      "   train_time: 1.592  loss_time: 1.044\n",
      "   train accuracy 0.24%  train loss 5.365\n",
      "epoch 1 (iter 400/3126)\n",
      "   train_time: 1.409  loss_time: 0.996\n",
      "   train accuracy 0.26%  train loss 5.324\n",
      "epoch 1 (iter 500/3126)\n",
      "   train_time: 1.414  loss_time: 1.014\n",
      "   train accuracy 0.25%  train loss 5.343\n",
      "epoch 1 (iter 600/3126)\n",
      "   train_time: 1.421  loss_time: 1.004\n",
      "   train accuracy 0.26%  train loss 5.301\n",
      "epoch 1 (iter 700/3126)\n",
      "   train_time: 1.407  loss_time: 1.022\n",
      "   train accuracy 0.26%  train loss 5.268\n",
      "epoch 1 (iter 800/3126)\n",
      "   train_time: 1.415  loss_time: 1.004\n",
      "   train accuracy 0.26%  train loss 5.274\n",
      "epoch 1 (iter 900/3126)\n",
      "   train_time: 1.394  loss_time: 1.000\n",
      "   train accuracy 0.26%  train loss 5.228\n",
      "epoch 1 (iter 1000/3126)\n",
      "   train_time: 1.394  loss_time: 0.988\n",
      "   train accuracy 0.27%  train loss 5.267\n",
      "epoch 1 (iter 1100/3126)\n",
      "   train_time: 1.395  loss_time: 1.006\n",
      "   train accuracy 0.23%  train loss 5.246\n",
      "epoch 1 (iter 1200/3126)\n",
      "   train_time: 1.395  loss_time: 1.013\n",
      "   train accuracy 0.10%  train loss 5.219\n",
      "epoch 1 (iter 1300/3126)\n",
      "   train_time: 1.401  loss_time: 1.026\n",
      "   train accuracy 0.11%  train loss 5.212\n",
      "epoch 1 (iter 1400/3126)\n",
      "   train_time: 1.394  loss_time: 1.010\n",
      "   train accuracy 0.11%  train loss 5.224\n",
      "epoch 1 (iter 1500/3126)\n",
      "   train_time: 1.397  loss_time: 1.014\n",
      "   train accuracy 0.12%  train loss 5.209\n",
      "epoch 1 (iter 1600/3126)\n",
      "   train_time: 1.392  loss_time: 1.007\n",
      "   train accuracy 0.11%  train loss 5.180\n",
      "epoch 1 (iter 1700/3126)\n",
      "   train_time: 1.392  loss_time: 0.997\n",
      "   train accuracy 0.11%  train loss 5.208\n",
      "epoch 1 (iter 1800/3126)\n",
      "   train_time: 1.407  loss_time: 1.020\n",
      "   train accuracy 0.11%  train loss 5.201\n",
      "epoch 1 (iter 1900/3126)\n",
      "   train_time: 1.394  loss_time: 1.005\n",
      "   train accuracy 0.12%  train loss 5.180\n",
      "epoch 1 (iter 2000/3126)\n",
      "   train_time: 1.395  loss_time: 1.003\n",
      "   train accuracy 0.12%  train loss 5.187\n",
      "epoch 1 (iter 2100/3126)\n",
      "   train_time: 1.395  loss_time: 0.976\n",
      "   train accuracy 0.12%  train loss 5.187\n",
      "epoch 1 (iter 2200/3126)\n",
      "   train_time: 1.398  loss_time: 1.006\n",
      "   train accuracy 0.14%  train loss 5.202\n",
      "epoch 1 (iter 2300/3126)\n",
      "   train_time: 1.389  loss_time: 1.001\n",
      "   train accuracy 0.14%  train loss 5.199\n",
      "epoch 1 (iter 2400/3126)\n",
      "   train_time: 1.389  loss_time: 1.006\n",
      "   train accuracy 0.13%  train loss 5.165\n",
      "epoch 1 (iter 2500/3126)\n",
      "   train_time: 1.393  loss_time: 0.995\n",
      "   train accuracy 0.13%  train loss 5.199\n",
      "epoch 1 (iter 2600/3126)\n",
      "   train_time: 1.393  loss_time: 0.992\n",
      "   train accuracy 0.16%  train loss 5.190\n",
      "epoch 1 (iter 2700/3126)\n",
      "   train_time: 1.392  loss_time: 1.009\n",
      "   train accuracy 0.14%  train loss 5.175\n",
      "epoch 1 (iter 2800/3126)\n",
      "   train_time: 1.390  loss_time: 0.997\n",
      "   train accuracy 0.16%  train loss 5.169\n",
      "epoch 1 (iter 2900/3126)\n",
      "   train_time: 1.391  loss_time: 1.007\n",
      "   train accuracy 0.15%  train loss 5.178\n",
      "epoch 1 (iter 3000/3126)\n",
      "   train_time: 1.398  loss_time: 1.010\n",
      "   train accuracy 0.18%  train loss 5.153\n",
      "epoch 1 (iter 3100/3126)\n",
      "   train_time: 1.396  loss_time: 0.999\n",
      "   train accuracy 0.15%  train loss 5.165\n",
      "epoch 2 (iter 0/3126)\n",
      "   train_time: 1.398  loss_time: 1.029\n",
      "   train accuracy 0.15%  train loss 5.173\n",
      "epoch 2 (iter 100/3126)\n",
      "   train_time: 1.391  loss_time: 1.015\n",
      "   train accuracy 0.14%  train loss 5.205\n",
      "epoch 2 (iter 200/3126)\n",
      "   train_time: 1.394  loss_time: 1.004\n",
      "   train accuracy 0.14%  train loss 5.185\n",
      "epoch 2 (iter 300/3126)\n",
      "   train_time: 1.389  loss_time: 1.007\n",
      "   train accuracy 0.13%  train loss 5.184\n",
      "epoch 2 (iter 400/3126)\n",
      "   train_time: 1.386  loss_time: 1.000\n",
      "   train accuracy 0.15%  train loss 5.164\n",
      "epoch 2 (iter 500/3126)\n",
      "   train_time: 1.388  loss_time: 1.023\n",
      "   train accuracy 0.17%  train loss 5.163\n",
      "epoch 2 (iter 600/3126)\n",
      "   train_time: 1.387  loss_time: 1.019\n",
      "   train accuracy 0.17%  train loss 5.149\n",
      "epoch 2 (iter 700/3126)\n",
      "   train_time: 1.392  loss_time: 1.028\n",
      "   train accuracy 0.15%  train loss 5.162\n",
      "epoch 2 (iter 800/3126)\n",
      "   train_time: 1.391  loss_time: 1.007\n",
      "   train accuracy 0.16%  train loss 5.159\n",
      "epoch 2 (iter 900/3126)\n",
      "   train_time: 1.389  loss_time: 1.004\n",
      "   train accuracy 0.14%  train loss 5.146\n",
      "epoch 2 (iter 1000/3126)\n",
      "   train_time: 1.388  loss_time: 1.003\n",
      "   train accuracy 0.16%  train loss 5.173\n",
      "epoch 2 (iter 1100/3126)\n",
      "   train_time: 1.388  loss_time: 1.014\n",
      "   train accuracy 0.14%  train loss 5.167\n",
      "epoch 2 (iter 1200/3126)\n",
      "   train_time: 1.389  loss_time: 1.012\n",
      "   train accuracy 0.17%  train loss 5.157\n",
      "epoch 2 (iter 1300/3126)\n",
      "   train_time: 1.394  loss_time: 1.002\n",
      "   train accuracy 0.21%  train loss 5.143\n",
      "epoch 2 (iter 1400/3126)\n",
      "   train_time: 1.390  loss_time: 0.995\n",
      "   train accuracy 0.17%  train loss 5.148\n",
      "epoch 2 (iter 1500/3126)\n",
      "   train_time: 1.390  loss_time: 1.005\n",
      "   train accuracy 0.25%  train loss 5.174\n",
      "epoch 2 (iter 1600/3126)\n",
      "   train_time: 1.394  loss_time: 0.998\n",
      "   train accuracy 0.23%  train loss 5.138\n",
      "epoch 2 (iter 1700/3126)\n",
      "   train_time: 1.389  loss_time: 1.007\n",
      "   train accuracy 0.17%  train loss 5.160\n",
      "epoch 2 (iter 1800/3126)\n",
      "   train_time: 1.389  loss_time: 1.017\n",
      "   train accuracy 0.24%  train loss 5.146\n",
      "epoch 2 (iter 1900/3126)\n",
      "   train_time: 1.388  loss_time: 1.006\n",
      "   train accuracy 0.15%  train loss 5.183\n",
      "epoch 2 (iter 2000/3126)\n",
      "   train_time: 1.388  loss_time: 1.002\n",
      "   train accuracy 0.15%  train loss 5.150\n",
      "epoch 2 (iter 2100/3126)\n",
      "   train_time: 1.386  loss_time: 1.005\n",
      "   train accuracy 0.15%  train loss 5.155\n",
      "epoch 2 (iter 2200/3126)\n",
      "   train_time: 1.388  loss_time: 1.000\n",
      "   train accuracy 0.15%  train loss 5.151\n",
      "epoch 2 (iter 2300/3126)\n",
      "   train_time: 1.388  loss_time: 1.008\n",
      "   train accuracy 0.23%  train loss 5.132\n",
      "epoch 2 (iter 2400/3126)\n",
      "   train_time: 1.393  loss_time: 1.016\n",
      "   train accuracy 0.24%  train loss 5.154\n",
      "epoch 2 (iter 2500/3126)\n",
      "   train_time: 1.389  loss_time: 1.005\n",
      "   train accuracy 0.18%  train loss 5.144\n",
      "epoch 2 (iter 2600/3126)\n",
      "   train_time: 1.393  loss_time: 1.002\n",
      "   train accuracy 0.16%  train loss 5.144\n",
      "epoch 2 (iter 2700/3126)\n",
      "   train_time: 1.390  loss_time: 0.989\n",
      "   train accuracy 0.23%  train loss 5.135\n",
      "epoch 2 (iter 2800/3126)\n",
      "   train_time: 1.463  loss_time: 1.010\n",
      "   train accuracy 0.20%  train loss 5.172\n",
      "epoch 2 (iter 2900/3126)\n",
      "   train_time: 1.407  loss_time: 1.008\n",
      "   train accuracy 0.26%  train loss 5.148\n",
      "epoch 2 (iter 3000/3126)\n",
      "   train_time: 1.438  loss_time: 1.015\n",
      "   train accuracy 0.26%  train loss 5.149\n",
      "epoch 2 (iter 3100/3126)\n",
      "   train_time: 1.480  loss_time: 1.061\n",
      "   train accuracy 0.22%  train loss 5.150\n",
      "Training done!\n",
      "Train Finish\n",
      "(Loss, Accuracy) on Training Dataset (0.0402, 0.00%)\n",
      "Time for trainset loss/acc : 3237.295\n",
      "(Loss, Accuracy) on Validataion Dataset (0.0403, 0.00%)\n",
      "Time for validset loss/acc : 79.035\n",
      "Total Time : 12246.345\n"
     ]
    }
   ],
   "source": [
    "# Clear old variables\n",
    "time_base = time.time()\n",
    "tf.reset_default_graph()    \n",
    "from captioning import *\n",
    "\n",
    "hidden_size = 512\n",
    "timesteps = 17\n",
    "n_words = 1004\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "# Declare out simple model\n",
    "print(\"Model Construct Start\")\n",
    "start_model = time.time()\n",
    "model = Captioning(batch_size = batch_size)\n",
    "print(\"Model Construct Finished || time consumed : %.3f\" % (time.time() - start_model))\n",
    "\n",
    "# Hyperparamters\n",
    "training_epochs = 2\n",
    "    \n",
    "conf = tf.ConfigProto()\n",
    "conf.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# Now, create a tf.Session and train the model\n",
    "with tf.Session(config=conf) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Train Start\")\n",
    "    run_model(sess, model, X_train, Y_train, epochs = training_epochs, is_training=True)\n",
    "    print(\"Train Finish\")\n",
    "    t_train = time.time()\n",
    "    print(\"(Loss, Accuracy) on Training Dataset (%.4f, %.2f%%)\" % run_model(sess, model, X_train, Y_train))\n",
    "    print(\"Time for trainset loss/acc : %.3f\" % (-t_train + time.time()))\n",
    "    t_valid = time.time()\n",
    "    print(\"(Loss, Accuracy) on Validataion Dataset (%.4f, %.2f%%)\" % run_model(sess, model, X_val, Y_val))\n",
    "    print(\"Time for validset loss/acc : %.3f\" % (-t_valid + time.time()))\n",
    "    print(\"Total Time : %.3f\" % (time.time() - time_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHjCAYAAACNTANBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3XmcXGWZ9//PVd1ZOkmHhGyEBAkggqyBJIoDouCIAs8MizCMG8oMMozIoM6CM6OP+FOeQXFEcCHDsAgzjCsKA2oUUIERERLIMiwaCYGEhKQhe7o7vd2/P+46qerq6u5azqmz1Pf9evWrumvpujvprv72dV3nPuacQ0RERETik4t7ASIiIiLNToFMREREJGYKZCIiIiIxUyATERERiZkCmYiIiEjMFMhEREREYqZAJiIiIhIzBTIRERGRmCmQiYiIiMSsNe4FVGv69Olu3rx5cS9DRBpo2bJlrzrnZsS9jjDoNUykuVT6+pW6QDZv3jyWLl0a9zJEpIHM7MW41xAWvYaJNJdKX7/UshQRERGJmQKZiIiISMwUyERERERilroZMpGk6u3tZf369XR3d8e9lNQaP348c+fOZcyYMXEvRSQx9NqSDvW+fimQiYRk/fr1tLe3M2/ePMws7uWkjnOO1157jfXr13PQQQfFvRyRxNBrS/KF8fqllqVISLq7u5k2bZpeMGtkZkybNk1VAJESem1JvjBevxTIREKkF8z66N9PpDz9bCRfvf9HCmQiIiIiMVMgE8mIbdu28c1vfrOmx55xxhls27at4vtfddVVfPnLX67pudLIzMab2eNmtsLMnjazz+Wv/5aZvWBmy/Nv8+Neq0jYGvna0swUyEQyYqQXzf7+/hEf+5Of/IQpU6ZEsays2AOc6pw7FpgPvNvMTsjf9vfOufn5t+XxLVEkGll8bXHOMTAwEPcyBtFRliIR+Ny9T/PMhh2hfs4j9p/MZ//kyGFv/9SnPsXzzz/P/Pnzeec738mZZ57J5z73OWbPns3y5ct55plnOPvss1m3bh3d3d1cccUVXHLJJUDhdD67du3i9NNP56STTuLRRx9lzpw53HPPPbS1tQ37vMuXL+fSSy+ls7OTQw45hFtvvZWpU6dyww03sHjxYlpbWzniiCP4zne+w0MPPcQVV1wB+HmLhx9+mPb29lD/naLgnHPArvyHY/JvLr4VSbP6+Mdhecixf/58+OpXh7+9ka8t9957L1/4whfo6elh2rRp3HnnncyaNYtdu3Zx+eWXs3TpUsyMz372s7znPe9hyZIl/NM//RP9/f1Mnz6dBx98kKuuuopJkybxd3/3dwAcddRR3HfffQCcfvrpnHLKKfzmN7/h7rvv5pprruGJJ56gq6uL8847j8997nMAPPHEE1xxxRXs3r2bcePG8eCDD3LGGWfwta99jfnzfSH8xBNP5MYbb+SYY44J5f9BFTKRjLjmmms45JBDWL58Oddeey0Ajz/+OFdffTXPPPMMALfeeivLli1j6dKl3HDDDbz22mtDPs/q1au57LLLePrpp5kyZQp33XXXiM974YUX8sUvfpGVK1dy9NFH731Bu+aaa3jqqadYuXIlixcvBuDLX/4y3/jGN1i+fDmPPPLIiEEvacysxcyWA5uB+51zv83fdLWZrTSz68xs3DCPvcTMlprZ0o6OjoatWSQMjXxtOemkk3jsscd46qmn+PM//3O+9KUvAfD5z3+effbZh1WrVrFy5UpOPfVUOjo6+MhHPsJdd93FihUr+P73vz/q1/K73/2OCy+8kKeeeooDDzyQq6++mqVLl7Jy5UoeeughVq5cSU9PDxdccAHXX389K1as4IEHHqCtrY2LL76Yb33rWwD8/ve/Z8+ePaGFMVCFTCQSI1WyGulNb3rToD1xbrjhBn70ox8BsG7dOlavXs20adMGPeaggw7a+xfgggULWLt27bCff/v27Wzbto23ve1tAHzoQx/i/PPPB+CYY47h/e9/P2effTZnn3024P+i/OQnP8n73/9+zj33XObOnRva1xo151w/MN/MpgA/MrOjgH8EXgHGAjcBVwL/X5nH3pS/nYULF6qyJjUbqZLVSFG9tqxfv54LLriAjRs30tPTs/c5HnjgAb7zne/svd/UqVO59957Ofnkk/feZ9999x113QceeCAnnHDC3o+/973vcdNNN9HX18fGjRt55plnMDNmz57NokWLAJg8eTIA559/Pp///Oe59tprufXWW/nwhz886vNVQxUykQybOHHi3vd/9atf8cADD/Cb3/yGFStWcNxxx5XdM2fcuEKRp6Wlhb6+vpqe+8c//jGXXXYZy5YtY8GCBfT19fGpT32Km2++ma6uLk444QSee+65mj53nJxz24BfAe92zm103h7gNuBNsS5OpEGiem25/PLL+djHPsaqVav4t3/7t72fxzk3ZFuJctcBtLa2DpoPK15L8bpfeOEFvvzlL/Pggw+ycuVKzjzzTLq7u4f9vBMmTOCd73wn99xzD9/73vd43/veV/bfplYKZCIZ0d7ezs6dO4e9ffv27UydOpUJEybw3HPP8dhjj9X9nPvssw9Tp07lkUceAeA//uM/eNvb3sbAwADr1q3jlFNO4Utf+hLbtm1j165dPP/88xx99NFceeWVLFy4MDWBzMxm5CtjmFkb8MfAc2Y2O3+dAWcD/xvfKkWi0cjXlu3btzNnzhwAbr/99r3Xn3baaXz961/f+/HWrVt5y1vewkMPPcQLL7wAwJYtWwA/t/bkk08C8OSTT+69vdSOHTuYOHEi++yzD5s2beKnP/0pAIcffjgbNmzgiSeeAGDnzp17w+PFF1/M3/zN37Bo0aKKKnLVUMtSJCOmTZvGiSeeyFFHHcXpp5/OmWeeOej2d7/73SxevJhjjjmGww47bFDZvh6333773qH+gw8+mNtuu43+/n4+8IEPsH37dpxzfOITn2DKlCl85jOf4Ze//CUtLS0cccQRnH766aGsoQFmA7ebWQv+D9nvOefuM7NfmNkMwIDlwKVxLlIkCo18bbnqqqs4//zzmTNnDieccMLeMPXpT3+ayy67jKOOOoqWlhY++9nPcu6553LTTTdx7rnnMjAwwMyZM7n//vt5z3vewx133MH8+fNZtGgRb3jDG8o+17HHHstxxx3HkUceycEHH8yJJ54IwNixY/nud7/L5ZdfTldXF21tbTzwwANMmjSJBQsWMHnyZC666KKav8bhmD94KBr5vyhvBo7CH5H0F86535Tc5+3AV/FHLb3qnHvbSJ9z4cKFbunSpaM+t3OOHd19jGvNMX5MS41fgUjlnn32Wd74xjfGvYzUK/fvaGbLnHMLY1pSqCp9DUsi50AbxjeeXluSY8OGDbz97W/nueeeI5cb2mSs5/Ur6pbl9cAS59zhwLHAs8U35gPbN4E/dc4dCZwf1hP39A9w7Od+zi3/U75UKSIildu1C+bOhfzctkjTueOOO3jzm9/M1VdfXTaM1SuylqWZTQZOBj4M4JzrAXpK7vY+4IfOuZfy99kc1vO35P+M6x/QAU0iIvVatgw2bICUjP2JhO7CCy/kwgsvjOzzR1khOxjoAG4zs6fM7GYzm1hynzcAU83sV2a2zMzKfqW17OHTkvOBrE+BTBooyhGAZqB/v+TKzzfT2RnvOpqVfjaSr97/oygDWStwPHCjc+44YDfwqTL3WQCcCbwL+IyZDZm+c87d5Jxb6JxbOGPGjIqe3MzIGQwokEmDjB8/ntdee00vnDVyzvHaa68xfvz4uJciZSiQxUevLckXxutXlEdZrgfWF+1m/QOGBrL1+EH+3cBuM3sYP2v2+zAW0JrL0a9vYGmQuXPnsn79erQTe+3Gjx+fqs1im4kCWXz02pIO9b5+RRbInHOvmNk6MzvMOfc74B3AMyV3uwf4upm14ne6fjNwXVhryOU0QyaNM2bMmEE7V4tkxauvQrCVkwJZ4+m1pTlEvQ/Z5cCdZjYWWANcZGaXAjjnFjvnnjWzJcBKYAC42TkX2saKrbmcApmISJ2Kd+no6opvHSJZFmkgc84tB0r33lhccp9rgWujeP6cqUImIlKvpUv9/mOvf70qZCJRyfRO/S05UyATEanTE0/AYYfBjBkKZCJRyfS5LFs01C8iUrcnnoBFi2DCBAUykahkPJBBf78CmYhIrV5+GTZuhIULFchEopTpQKZtL0RE6hNsd7FoEbS1KZCJRCXTgUzbXoiI1OeJJ6C1FebPV4VMJEqZDmQtpqF+EZF6PPEEHHWUr44pkIlEJ9uBLGdqWYqI1Mg5v+XFokX+YwUykehkP5BpqF9EpCIPPwxvfjP87Gf+4+efh61bBwey3l7/JiLhyvg+ZBrqFxGpRH8/fOxjsGoVvPvd8NGPwvHH+9uKAxn43frHjIlnnSJZlfFApqF+EZFK/Od/+jB2++2wfDlcd50/MGr8eDjySH+fIJB1dsLkyfGtVSSLst2y1FC/iMiourrgM5/xlbAPfhC+8hX4xS9g7lw45ZRCNaw4kIlIuDJeITMG1LIUERnR174G69bBHXf4c1aCD2Jr1kBfX+F+CmQi0cl8IOvTUL+IyLC2bIF/+Rc44wx4+9sH39bS4t8CxTNkIhKubLcste2FiMiwnIOrr4bt2+Gaa0a/vypkItHJfIWst3cg7mWIiCTGyy/DXXfBr3/t315+GT78YTj66NEfq0AmEp2MB7Ic/QP9cS9DRCQx/vqv4d574YAD4K1vhZNOgosuquyxCmQi0cl2IDNteyEiUuy55+Dcc32VrFoKZCLRyf4MmQKZiAjgN39duxYOPbS2x7e1+UsFMpHwZT6QadsLERFv/Xp/2qNDDqnt8aqQiUQn84GsTxUyERHAn5sSFMhEkijjgSzHgAKZiAhQCGQHH1zb48eM8fuSKZCJhC/bgcxQhUxEJO/5532oOuCA2h5v5qtkCmQi4ct0IMtpqF9EZK81a2DevMG771dLgUwkGpkOZK0a6hcR2ev552tvVwYUyKSZOAef/CRcdVX0z5XpQKahfhERzzkfyGod6A8okEkzueMOuO46+OlPo3+uzAcyDfWLSLN56inYvXvwdVu2+HNWhhHIdHJxaQarV8Nll/n3G/FHSLYDmalCJiLNpbMTTjgBvvjFwdevWeMvVSETGV1PD7z3vTB2LLztbQpkdcupQiYiTebFF/0vk4cfHnx9vVteBBTIpBl8+tOwbBnccos/s0UjqsKZDmStOaNfQ/0i0kTWrvWXjz/ud+UPKJCJVOaxx+Daa+HSS+Gccxr3PZ/pQJbTUL+INJkgkHV1wfLlheuffx722w8mTqzv8yuQSdYtW+Yv/+//9ZcKZCFoVctSRJrM2rWQy7+y//rXhevXrKl/fgz8CcYVyCTL9uzxl8GpwiZM8NXm4opzFDIdyDTULyLN5sUXfVvywAPh0UcL14exBxmoQibZ19PjL8eN85dBMIt6jqw12k8fr1zOABgYcHvfFxHJsrVr/W78M2fCr37l9x/bswdefjmcClkQyJzzp1ISyZqgQjZ2rL8MAllnJ0yeHN3zZrpC1poPYRrsF5FmsXatr4790R/Bhg3w0kvwwgs+QIUVyPr7o2/fiMRlzx5obS20/tva/KUqZHUIqmL9A44xdZy7TUQkDbq6YNMmXyE78UR/3a9/Dfvs498Pq2UJvloQVBBEsmTPnkK7EgZ/z0epOSpkmiMTkSbw0kv+ct48OOoomDTJz5EFW16EVSEDzZFJdvX0xBPIsl0hyw84aLBfRJpBsOXFvHm+5fLmN/sKWUuL3+5i5sz6n0OBTLJuz57B1V9VyELQWjTULyKSdcWBDHzbcuVKWLHCV8fCGMJXIJOsU8syAi0a6heRJrJ2ra+MzZ7tP/6jP4KBAX8apTDmx6BxWwBIutx/PyxeHPcqwhFXyzLTgSynGTIRaSIvvgive51vUYI/ybhZeEdYgipkUt5tt8HnPx/3KsJRWiFr1FGWmQ5kGuoXkWYS7EEW2GcfP9wPCmQSrd5e2LIl7lWEQzNkEQiG+hXIRKQZlAYyKGx/oUAmUerpge7ubLSyNUMWgdYWBTIRaQ7d3bBxo98Utti73gVjxsCRR4bzPApkUk6wUXAWqmSaIYvA3gqZhvpFJOOK9yArdtZZ8MorMGdOOM+jQCblBIHstdfiXUcYSitkY8f6XfsVyOrQohkyEWkSL77oL0sDmRnsu294zxMMOCuQSbEsVchKZ8jMCudwjVKkgczMppjZD8zsOTN71szeMsz9FplZv5mdF+bza6hfRJpF6R5kUVEgk3KyFsiKK2Tgv+/Tfi7L64ElzrnzzGwsMKH0DmbWAnwR+FnYT66hfhFpFsEeZPvvH+3zjBnj3xTIpFiWAlnpDBmkvEJmZpOBk4FbAJxzPc65bWXuejlwF7A57DVoqF9EmsXatTB3rg9lUWvELydJl6zNkBW3LCHlgQw4GOgAbjOzp8zsZjObWHwHM5sDnAOMuL+vmV1iZkvNbGlHR0fFC9C5LEWkWbz4YvTtyoACmZTKUoWsXMsy7YGsFTgeuNE5dxywG/hUyX2+ClzpnOsf6RM5525yzi10zi2cMWNGxQsIhvoHdJSliGRcuT3IoqJAJqUUyOoXZXF7PbDeOffb/Mc/YGggWwh8x3wlazpwhpn1OefuDmMBOspSRJrBnj2wYYMCmcQnS4FsuBmyrVujfd7IAplz7hUzW2dmhznnfge8A3im5D4HBe+b2beA+8IKYwAtGuoXkSawbp0/X2XpprBRmTAhGzuyS3h6evxl2gOZc+VnyNra/B89UYp6/PNy4M78EZZrgIvM7FIA51zk54XXUL+INIPh9iCLiipkUiorQ/3B15G1liXOueX4tmSxskHMOffhsJ9f216ISDNo1B5kgQkT/O7/IoGstCz37PGXWRvqj51myESkGaxdCy0tftuLRlCFTEplJZAFrVcFspDtDWQ6ylJEMuyFF/y5KhuxBxkokMlQvb3+FENdXemeLwwqZFnbhyx2qpCJSNYNDMAvfwkLS4dDIqRAJqV6e2H6dP9+1EcjRmmklmVvL/T1RffcmQ5kOpeliGTd0qX+6K+zz27cc7a1KZBJwcCAf5s1y3+c5sH+kVqWEG31L9OBTEP9IpJ199zj58fOPLNxzxlUyDQNIlCYH9tvP3+Z5jmy4SpkbW3+Mso/RDIdyFpz/stTIBORrLrnHjj5ZNh338Y954QJhf2aRIJAFlTIshDIys2QgQJZzfJ5TEP9IpJJf/gDPP00nHVWY5+3Eb+cJD2yGMiGa1kqkNVIQ/0ikmX33OMvFcgkTsHcVTPMkCmQ1UiBTESy7O674dhjG7chbECBTIoFFbKpU2HMmGxUyNSyDJnOZSkiWdXRAY8+2vjqGCiQyWBBIBs7FqZNy0Yg01GWIdNQv4hk1X33+a0GGrndRaARv5wkPYJANmaMP7gki4FMR1nWKRjqH9BQv4ik3Kc/DddeC9u3+4/vvhte9zqYP7/xa1GFTIplKZDFOUPWoBNtxCOYIetThUxEUmxgAK6+2r//hS/AJZfA/ffDX/6lP11NoymQSbHSQBac7D6N4pwha4pAppaliKRZf7+/fP/7/ftf+YoPaXHMj4ECmQxWHMimTYMnn4x3PfXQthcR0VC/iGRBcP68o46Cb3/b7z/2X/8F73hHPOtRIJNiWWpZxhnIVCETEUm4oELW0uIvDzrIv8VFgUyKlQayzk7o7obx4+NdVy2GmyEbO9bPpesoyxqZGTnTUL+IpFtQIWtNyJ/QCmRSrDSQAWzd2vh13HefryDXY7gZMjN/pKUqZHVoyZmG+kUk1YIKWVICWSO2AJD0CKpKwQwZ+N36Z89u7Dquusr/8fLe99b+Ofbs8T9nuTLlqgkTNENWl5acMaBAJiIpFlTIgpZl3HI539JRIBMoXyFr9BxZTw+sWlX/Ce/37BnargwokNWpxVQhE5F0S1qFDKL/5STpUbxTfyWBbMsWePnlcNfw9NM+lNUbyHp6FMgi05IzDfWLSKolrUIGCmRSUG2F7B/+Ac49N9w1LFvmL8OokJXOjwUUyOqkQCYi9TKz8Wb2uJmtMLOnzexz+esPMrPfmtlqM/uumQ3zUl4fVcgkyUr3IQM/QzacV18Nv6UZ7H0WdctSR1nWoSVn9OsoSxGpzx7gVOfcscB84N1mdgLwReA659yhwFbgL6N4clXIJMmKA9nEif5ypMDV21t4TFjCrJANF8iiPsqyKQKZhvpFpB7O25X/cEz+zQGnAj/IX387EMmpvpNaIdPJxQUGBzKz0TeH7ekp/JER1vOvWOHfD2OGTC3LiGioX0TCYGYtZrYc2AzcDzwPbHPOBb9a1gNzhnnsJWa21MyWdnR0VP3cqpBJkhUHMqgskIVZIXv2WR/E3vAG/3kHBmr/XDrKMkItLaqQiUj9nHP9zrn5wFzgTcAby91tmMfe5Jxb6JxbOGPGjKqfO6kVMgUygaGBbNq0xlbIgvmxt7yl8PlrpUAWIVXIRCRMzrltwK+AE4ApZhbEpLnAhiieUxUySbJyFbKRhvrDniFbtgwmTfLneoX62pba9iJCGuoXkXqZ2Qwzm5J/vw34Y+BZ4JfAefm7fQi4J4rnT9qpk0CBTAqKd+qHxs+QLVsGxx1XOINEvRWykWbIdJRlHTTULyIhmA380sxWAk8A9zvn7gOuBD5pZn8ApgG3RPHkallKkgXVrqCC28hA1t8Py5fD8ccXglQ9FbLRjrIMO0wWS9CPdzRyalmKSJ2ccyuB48pcvwY/TxYptSwlyXp7C0dYgp8h2717+HATDPU7V3hMrZ57zletFizwnw+iC2QTJvjLri5ob6/9OYaT+QpZq4b6RSTlklgha2vzv5jqOaJNsqG3d3Cbb7Td+oOWYhjfO8FA//HHF4JUlDNkEN0fIpkPZBrqF5G0S2qFDKC7O951SPyCCllgtEAWtDjDGOxftsz/cXD44eEEstFmyECBrGYtOWNAQ/0ikmJJrJBF/ctJ0qPaQBZUyMKYxXrySZg/3/+xUk0gW7IEfvSjoddX0rJUIKuRzmUpImmXxApZGNUIyYbSQBacz3K0QFZvhWxgAJ56ys+PQXXfk1/5CnzhC0Ovr3SGLAqZD2Qa6heRtEtihSwIh8HapHnFVSFbvRp27fLzY1BdIOvp8QcelLt+pKMsQRWymmmoX0TSLokVMgUyCQwXyMptDutc4fu53kC2cqW/nD/fX1YbyHbtGnydc5ohi5QqZCKSdkmskAVriWpPJkmP0kA2aZIP7Fu3lr9vufdrEQSqqVP9ZTWBrLd3aIUsWI9myCLSqqF+EUk5VcgkyXp6BgcyMxg/vnwwKt5Fv94wX3rKploqZMXxIHicAllENNQvImmXxFMnKZBJoLRCBr7tV+4URsXX1VshqyeQ9fb6n6vi9QTvq2UZkZwpkIlIugWhRxUySaJqAllxCIuzQhY8trhtWWmFTEdZ1qi1RYFMRNJNFTJJsnKBbNy40VuWcVbIgnUUD/aPFsh0lGWdVCETkbRL4lC/ApkESk+dBJW1LNNWIRs3zs/HKZDVqDVn9GuoX0RSTEP9kmTDVcjSEMiKK2SjzZCZ+balAlmNchrqF5GUU4VMkmy4GbJywSjMbS96eyGX82/gvydbWqprWVZTIYMUBzIzm2JmPzCz58zsWTN7S8nt7zezlfm3R83s2LDX0KKWpYiknCpkkmS1HmVZb4WsdLsNGH52rVS5ClncgSzqv7euB5Y4584zs7HAhJLbXwDe5pzbamanAzcBbw5zARrqF5G0S2KFTBvDSiDOof44AllUR1lG9uNtZpOBk4EPAzjneoBBedk592jRh48Bc8Neh4b6RSTtVCGTJCtXqRo7tnwlKewZskpbpcWKT99U3LIcbYYM/JGWaWxZHgx0ALeZ2VNmdrOZTRzh/n8J/LTcDWZ2iZktNbOlHR0dVS1CQ/0iknZJrJApkEmg1n3IoqqQlXve4daQpJZllIGsFTgeuNE5dxywG/hUuTua2Sn4QHZlududczc55xY65xbOmDGjqkVoqF9E0i74az6XoMOwFMgkUGvLMooKWSUty+I1NMtQ/3pgvXPut/mPf4APaIOY2THAzcBZzrky54avT6sCmYikXH+/D0Bmca+kQIFMAnEN9dcayIarkAVry1wgc869Aqwzs8PyV70DeKb4Pmb2OuCHwAedc7+PYh2qkIlI2vX1JWt+DBTIpCBtQ/3Fz1uuQjbSDFmaj7K8HLgzf4TlGuAiM7sUwDm3GPi/wDTgm+b/9Otzzi0McwHa9kJE0q6vL1nzY6BAJgVxnsuy3pZlUxxlCeCcWw6UBqzFRbdfDFwc5Ro01C8iadffr0AmyVXrqZOSUCFrlqH+RMjlDOdgQFUyEUmpJLYstQ+ZgN9Cor8/XUP9w7Uss7ztRSK05vwUrKpkIpJWqpBJUpWeTzKQ5ApZvS3Lnp5o/hDJfCDLBYFMFTIRSakkVsgUyASGD2RBMCqthSRhhmykof7W1pG3l5mQP99QFHNkmQ9kLaZAJiLppgqZJFVQbSpXIYOhoSsJLctgDRMnDq2QjVQdg0Igi6Jtmf1AppaliKScKmSSVCO1LGFo2zIJLcvgeadOHTpDNtL8GKhCVpe9gaxfgUxE0kkVMkmqkVqWMDQc9fQUWoJxtyynTlWFrKE01C8iaacKmSRVtRWy3l4fenK5+If6awlkbW3+UoGsBsFQv7a9EJG0UoVMkmq0QFauQjZ2rL9/Eipkvb2FgKYKWcSCof4+BTIRSSlVyCSpRmtZlpshGzvW/4ERVYWsrw8GBkZf89Sp/jKYI6tmhkyBrAYt2vZCRFIuiadO0sawAoVwU26nfigfyMaMibZCBiNXyYpbllAIZKqQRUyBTETSrr9fFTJJpmqH+oPTLLW2xhfISitkwRxZNYFMR1nWQNteiEjaJbFCpkAmUNu2F1G2LIebXSt9HKhC1nAtGuoXkZTTUL8kVRKH+ss9b+kaAKZM8ZdBhaySGbKJE2Hu3NHvV4uE/YiHT0P9IpJ2SRzqD/aSUiBrbsPt1D/SUP+YMdEO9Zd73tLHAey7r7+spmU5ZQqsW1f9WivRNBUyzZCJSFolsUIGPiQqkDW3WvYhS0qFrJa5knrHAAAgAElEQVSWZZQUyEREEi6JFTJQIJPaW5b1VsgGBvxb2EP9UbQiK9U8gUxD/SKSUqqQSVLVug9ZvRWyao/uLPfYcvuQqUIWIQ31i0jaqUImSVVLhSyYIYsrkAUhcfJkf1nNDFmUmiaQaahfRNIqqRWyMPaSknSrtkJWvA9ZPS3LeitkY8fC+PH+4BTNkDVIcJSlKmQiklaqkElS1boPWdwtyzFjwAwmTapu24soZT+QqUImIimX1AqZApmMduqkqIb6621ZBo8LAplzqpBFTkP9IpJ2qpBJUqV1qD8IjBMn+pZl8PkUyCKkoX4RSbsknjoJFMik+qH+oF2YtApZcH8FsgipZSkiaaeWpSTVcDv153L+ezapFbLgcUGFLFinZsgipAqZiKSdWpaSVMMFI/DhZqSTiyehZakKWQPpXJYiknaqkElSBcGo3Pfn2LHpGOrfvVuBrCH2Vsg01C8iKaUKmSRVb68PV/naxyDjxpXfh2zMmPhblsVD/aqQNYjOZSkiaZfUCpk2hpVyJ/gOlFbI+vv9+SejrJAFs2uVzpAFLUvNkDWAhvpFJO1UIZOkGi2QFVfIikNPVBUy8FWuSluWwVC/KmQNoKF+EUm7pFbIFMiay3nnwQ9+MPi6kQJZacuyOJBFVSELPn81Q/179hROn6RAFiEN9YtI2qlCJnFzDu6+Gx5+ePD11bQsi0NUkipkAFu2FNYcl+wHMg31i0iKOefnblQhkzj19vr/687OodcPF2JGq5DFFchKZ8igEMhUIYvQ3hmyfgUyEUmfIPCoQiZxCoJY0NoL1DpDFmXLstzRnaWPLW5ZggJZQ6hCJiJpFlQRVCGTOHV1+cvSQFbc/itV2rJM6lA/wGuvFR4bl6YJZNr2QkTSSBUySYJaKmSllariEBW0LGutldTbshyuQqYZsghp2wsRSbMkV8haWxXImsVwFbJqhvpLK2RQ+/dPWDNkpUP9qpBFKDjKUtteiEgaBb+wkhjIWlq0MWyzCKNCVjpDFjy+FmG1LDVD1kCqkIlImgWBRy1LiVOtFbKRNoaF2gN92C1LzZA1gJmRMw31i0g6Jb1CpkDWHGo9ynK4fciC7+e4Apn2IYtJS8401C8iqaQKmSSBWpbRUyATEUkwVcgkCYKWZWfn4CMj6x3qj7tlOX48mPmvr7XVn5w8Ls0RyEyBTETSSRUySYKgQuZcIZxBfRvDBo+vRW+vD1Llfi5GCmT9/f7MF8GazQpVsjirY9AkgSyXMw31i0gqqUImSVAcwopPn1TJqZOCilrpuSyhvgrZSK3S4QJZucpaMEcW5/wYNEkga82ZhvpFJJVUIZMkKA5hxXNko+3U71zhezjsCtlIQXC0QFb8WFXIGkgzZCKSVkmukGlj2OYxXCAbrVIFhSAW9gxZLRWyYA3Fj22KQGZmU8zsB2b2nJk9a2ZvKbndzOwGM/uDma00s+OjWIcCmYikVdIrZNoYtjkUtywrDWRBFSoIR+UqZFEFsv7+8n8slKuQNUvL8npgiXPucOBY4NmS208HDs2/XQLcGMUiNNQvImmV5FMnqWXZPGqpkAUBJwhixWEojJblaJW5clWycjNkma+Qmdlk4GTgFgDnXI9zblvJ3c4C7nDeY8AUM5sd9lpyqpCJSErp5OKSBLVUyIZrWUY91F9amStWrmUZVMgyG8iAg4EO4DYze8rMbjaziSX3mQOsK/p4ff66QczsEjNbamZLOzo6ql5Ia87o11C/iKSQKmSSBPVUyEZqWcZVIWu2of5W4HjgRufcccBu4FMl97EyjxuSnJxzNznnFjrnFs6YMaPqhahCJiJpleShfgWy5tHVBVOn+vdrbVn29BT2Dot6qB+qr5BleYZsPbDeOffb/Mc/wAe00vscUPTxXGBD2AtpVSATkZRK+lC/Allz6OyEoB4SBLJgS4tKg1GwVYVZ/BWyppohc869Aqwzs8PyV70DeKbkbv8NXJg/2vIEYLtzbmPYa8lpqF9EUkoVMkmCcoEs+GOhmgpZcN+oj7KE9LUso/4Rvxy408zGAmuAi8zsUgDn3GLgJ8AZwB+ATuCiKBahbS9EJK1UIZMk6OqCA/L9rGCerFy4KVZuqD+4byNalsWnbQokeag/0kDmnFsOLCy5enHR7Q64LMo1gIb6RSS9klwh08awzaOzEyZM8G9BhaxcuClWbqg/uC6JLcssz5Alhob6RSStkl4hc86frFmyravLh7GJEwuBrFy4KVZuH7JGVsgqbVkmpULWFIFMQ/0iklZJrpAFIVFVsuzr7IS2tuoCWWkwKjdD1ugKWdOeOikpNNQvImmV9AoZKJA1g6BlWU+FrNEzZGkb6m+KQNbaokAmIumkCpnEzbnaWpYjDfUnaYasGfYhS4ycaahfRNJJFTKJW3e3v6y2ZVk61F88QxbXthdqWcZM216ISD3M7AAz+6WZPWtmT5vZFfnrrzKzl81sef7tjLCfO+mnTgIFsqwLzmMZRssyuG+SWpZJGepP4I94+DTULyJ16gP+1jn3pJm1A8vM7P78bdc5574c1ROrZSlxC/YdC2OoP+6W5UgVsrhblgn8EQ+fhvpFpB75M4hszL+/08yeBeY04rnVspS4hVkhmzx58GPiqpAVP3b6dLj0UnjXu2pbS1iaomWpoX4RCYuZzQOOA4Lz9H7MzFaa2a1mNjXs50tyhSxYkwJZtgUVstJAVunGsOX2IYt7qL+4GpbLwY03wjHH1LaWsDRFINNQv4iEwcwmAXcBH3fO7QBuBA4B5uMraP86zOMuMbOlZra0o6OjqudMQ4Ws1iqHpENxy3LChMpPndTS4t9G2ocsigpZ6cEExUYLkXFqikCmoX4RATCzu8zsTDOr+rXPzMbgw9idzrkfAjjnNjnn+p1zA8C/A28q91jn3E3OuYXOuYUzgjM0VyjJFTK1LJtDacuyp8cHqdFaluDDUbltL8z8908UFbJczt9WacsyKRTIRKSZ3Ai8D1htZteY2eGVPMjMDLgFeNY595Wi62cX3e0c4H/DXCyko0KmQJZtpUP94NuWlYSbcePKD/WD/yMjigoZ+OcZLpDlcsn8eUrg31zhazFjQIFMpOk55x4AHjCzfYD3Aveb2Tp8des/nXPD/b1+IvBBYJWZLc9f90/Ae81sPuCAtcBfhb1mVcgkbqUVMqg8kBVXyIpnyILH1RLInPPfc5UGwWLFbdOkSeCPePhaW4w+BTIRAcxsGvABfMB6CrgTOAn4EPD2co9xzv0PYGVu+kk0qyxQhUziVjrUD7UFstIw1NpaW8uy2spc6WPj3t5iOE0RyHJmDGioX6TpmdkPgcOB/wD+JL+dBcB3zWxpfCsbXn+/b7FYuTgYMwWy5hBVy7LWClk9gUwVspi15FQhExEAvu6c+0W5G5xzCxu9mEr09SWzOgYKZM0irJZluRmyOCpkSQ1kGuoXkWbyRjObEnxgZlPN7KNxLmg0fX3JnB8DBbJmUW+FLOwZsqy2LJsjkGmoX0S8jzjntgUfOOe2Ah+JcT2j6u9PboVMG8M2h64u/389ZkxtFbI9e/wgfmkYirpCFgTBYkluWTZHINNQv4h4ufwWFgCYWQuQ0L+XvTRUyLQxbLZ1dvrqGAwOZJVsshq0LMuFqFq3vchqyzKhP+bhatFQv4h4PwO+Z2aL8VtVXAosiXdJI+vvT34gU4Us27q6/PwYFC47OysPRl1dhfDWyJZlMPtW+tiktiwT+mMeLg31i0jelfi9wv4av43Fz4GbY13RKDTUL3Hr7CwEsXIty5ECztixsH17+ftG3bLctm3o9UluWTZNIHMOnHNYEo8dF5GGyJ/i6Mb8WyqoQiZxG65lGVS3KmlZxlEhS9tQf0J/zMPVkg9h/QOO1hYFMpFmZWaHAv8CHAGMD653zh0c26JGoQqZxK24ZTlmjH/bvbtwCqKR6hxBMCo3b6ZtLwaraKjfzK4ws8nm3WJmT5rZaVEvLiwt+RCmtqVI07sNXx3rA04B7sBvEptYqpBJ3IorZOCrZEHLcrRwk7QKWZJblpUeZfkXzrkdwGnADOAi4JrIVhWyoEKmwX6RptfmnHsQMOfci865q4BTY17TiFQhk7gVV8igukAWBKM4Zsiy2rIMCpJnALc551ZYioaxWnKqkIkIAN1mlgNWm9nHgJeBmTGvaURJrpBpH7Lm0NkJ++9f+DgIZG1t9VXIWlvLHwk5mmavkC0zs5/jA9nPzKwdGIhuWeEKApk2hxVpeh8HJgB/AyzAn2T8Q7GuaBRpqJBpH7JsC7NlWXz/uIb6kxrIKv276y+B+cAa51ynme2Lb1umQhDIdPokkeaV3wT2z5xzfw/sIiWvYUmukKll2RzCaFkOVyFTy7Kg0grZW4DfOee2mdkHgE8D26NbVrgUyETEOdcPLEjTuAWko0KmQJZtw1XIKmn/xTnUPzAw9PNnoWV5I9BpZscC/wC8iD86KRX2bnuhoX6RZvcUcI+ZfdDMzg3e4l7USNJw6iQFsmwrrZBNmFBdy9K5wgnKG1UhC56ntEqW5ApZpT/mfc45Z2ZnAdc7524xs0TPXRTbO9Tfr0Am0uT2BV5j8JGVDvhhPMsZnVqWEqf+fh9qSluWwamTKmlZAuza5S8bOUMGfu3BZrbBY5NaIav0x3ynmf0j8EHgrflZjIR+SUPtHepXhUykqTnnUjE3VkwtS4lTd7e/HG6of7RqU3B7EMgaOUMGQytkSW5ZVhrILgDeh9+P7BUzex1wbXTLCpdmyEQEwMxuw1fEBnHO/UUMy6lIf39yWywKZNkXtBrrGeqH4QNZIypkpY9N6s9TRYEsH8LuBBaZ2f8BHnfOpWeGTIFMRLz7it4fD5wDbIhpLRXp6xtcnUgSBbLsCwJZaYWss7PyoX4oH8ga1bIslvoKmZn9Gb4i9iv8JrFfM7O/d879IMK1hUZD/SIC4Jy7q/hjM/s28EBMy6lIkmfItDFs9gUbt5ZWyJyDnTth0qSRHx8EsJ07/WUjz2UJgwOZc9mYIftnYJFzbjOAmc3Av4ilI5BpqF9EyjsUeF3cixhJGmbItDFsdg1XIQPYtg2mTh358SO1LBtdIQv+cEh1yxLIBWEs7zUq3zIjdhrqFxEAM9vJ4BmyV4ArY1pORZJcIVPLMvuGq5CBD2SVtix37x78MTSmQhbsf1b8ftorZEvM7GfAt/MfXwD8JJolhS+nc1mKCOCca497DdVKQ4VMgSy7hhvqh8oCWRCMgpZlnBWySh4Xp4qqXPlTjdwEHAMcC9zknEv0X5XFWnUuSxEBzOwcM9un6OMpZnZ2nGsajSpkEqeRWpZ9fdUP9ZfOkPX3+9muavT2gtnIf6iMFMiS2rKsuO3onLvLOfdJ59wnnHM/inJRYds71K9AJtLsPuuc23vaN+fcNuCzMa5nVKqQpcuVV8Ltt8e9ivCUa1kWv19vIIPqq2TVbLdRHMiS3rIcMZCZ2U4z21HmbaeZ7WjUIuulbS9EJK/ca15C60+eTp2ULnfeCffeG/cqwjNShQyq24estRVyRT+BwWMbFciSXiEb8cc8jfMW5ewNZBrqF2l2S83sK8A38MP9lwPL4l3SyPr7k1shC365KpAV7Njh37JipKF+qG6n/tL7Bn9o9PZWt9devYEslRWyrNBQv4jkXQ70AN8Fvgd0AZfFuqJRJLlCZuZDmQKZNzDgh9eDAfYsGGmoHypvWe7cOTSQNbpClvSWZUJ/zMOloX4RAXDO7QY+Ffc6qpHkoX4oDGZLYU4qS4EsqJCF0bIsDnUwuEJWjay2LJujQqahfhEBzOx+M5tS9PHU/JY+iZXkoX7wa9PGsF4QxLIUyDo7fbgpnv2qpUK2e7cqZKOJ9O8uM1sL7AT6gT7n3MKS2/cB/hO/U3Yr8GXn3G1hr6O1RYFMRACYnj+yEgDn3FYzmxnngkaT9ApZS4sqZIFgdixLM2SdnUPnu9rafLvaucqDEYw8Q1aNSgJZEBqLw3HSZ8ga8WN+inPu1WFuuwx4xjn3J/nTMf3OzO50zvUMc/+a6FyWIpI3YGavc869BGBm8xi8c3/ipKFCpkDmBUFs504fVvK/elKtq2toq9HMX7d7d+UVstL3IdptL1paYPJk2Lp18OPKrSMp4v67ywHtZmbAJGALEHrxW9teiEjePwP/Y2YP5T8+GbgkxvWMShWy9AgCWX8/dHdXd+RgUnV2Dg1k4CtQ1Qay0vtG2bIEmDLFn00gkPSWZdQzZA74uZktM7NyL3pfB94IbABWAVc45wZK72Rml5jZUjNb2tHRUfUiFMhEBMA5twRYCPwOf6Tl3+KPtEwsVcjSo7g9lpU5sq6u8sEyaAkmtWUJ/sTnqpAVnOic25Cf0bjfzJ5zzj1cdPu7gOXAqcAh+fs84pwb1IF3zt2EP3UTCxcurDpVaahfRADM7GLgCmAu/rXnBOA3+NegxHFOFbI0KZ4d27kTZiZ6OrEyw1XIgusqaR3mcn5LkEYO9cPwgawpK2TOuQ35y83Aj4A3ldzlIuCHzvsD8AJweNjr0FC/iORdASwCXnTOnQIcB1Rfdm+QgXy/QBWydCgOZFkZ7C831A+VV8igUCWLu0LWtC1LM5toZu3B+8BpwP+W3O0l4B35+8wCDgPWhL0WDfWLSF63c64bwMzGOeeew7/uJFIQdFQhS4estiyHmyGDysJNEMQaPUOmlmXBLOBHfl6fVuC/nHNLzOxSAOfcYuDzwLfMbBVgwJUjHJFZM82QiUje+vw+ZHfjRyS24mdYEyn4RZXkCpk2hi0obVlmwUhD/VBZuAnuE2aFbNKk0e+XtgpZZIHMObcGOLbM9YuL3t+Ar5xFSoFMRACcc+fk373KzH4J7AMsiXFJIwoCWdIrZNoY1stiIKt3qB9Gb1lGeZRlV5ffHHbcuOTPkCX4xzw8OQUyESnhnHto9HvFSy3LdNmxA8aP91teZGmGLKyWZRxD/eC3vpg1K/kty6Y4dVKrApmIpFAaWpYKZAU7d8KcOYX3syCMCtlwM2SNGOqHQtsy6S3LpghkOQ31i0gKqUKWLjt2wOzZ/v2sBLIwKmTDtSwbVSELAlnSW5ZNEcj2Vsj6FchEJD1UIUuXHTv83NLEidkIZL29/nswrApZHNtewNBAppZljPYO9atCJiIpogpZuuzY4c+fOHlyNmbIuvLnsMhKhUwtywQwM8xgQDNkIpIiqpCly86dPoy1t2ejQtbZ6S+j2ocs6grZlCn+MjifZW+vf86knvS9KQIZ+LZlnwKZiKSIKmTpsmOHD2NZCWRBhaxcy7LSUyfB6C3LRlbIklodgyYKZDkztSxFJFXSUCHTxrBeb6/f7qJZKmTt7f6y+OThwwm7ZVlpsBo71q+9eIZMgSwBWnOmoX4RSZW0VMi0MWwhgGUxkJWrkJ12Glx3HRx33OifJ66hfhi8W39vb3IH+qGJAlkupwqZiKRLGipkall6wRB/swz1t7XBxz9e2fdmmOeydM5/v9USyNSyTIiWnGmoX0RSJS2nTlIgKwSwLM2QjdSyrMZop06qpkJW7V5ipRUyBbIE0FC/iKRNEHRUIUu+4gpZVgLZSEP91Qjz1EnVBrIpU9SyTJycGQNqWYpIiqhClh6lM2Td3dXPRiVNVipkwbYXalkmRGvO6NNQv4ikSFqG+hXIBrcsJ0/276e9ShZ2haw0DAWV3ygrZGpZJpCG+kUkbTTUnx6lLUtIfyALq0I2XMvSzP+xEXUg27nTP4dalgnRmjP6NUMmIimShgqZ9iHzSluWxddF7bnn4L//O/zPG3XLEvz3T9QtS/Bty6S3LBP8Yx6unAKZiKSMKmTpEVTIJk1qbCDbswfOOgs2bgx/q42uLl/FqmTz15EMVyEDH5CirpCBb1uqQpYQLRrqF5GUSUOFTBvDejt2+DCWyxVmyBqxF9kXvwi//70Pf2EHwM5OPz9W77kf46yQBeez3Lo1+RWy5glkGuoXkZRRhSw9duwoBLFGVchWr4b/9/9g+nT/8YYN4X7+rq76B/ph+KH+4LpGVMi2bdNQf2K05FQhE5F0SUuFTIHMh69GBjLn4K//2lefrr/eXxd2INu9u/75MRi5ZdmoGbI0tCwT/GMeLm0MKyJpowpZejS6Qvbtb8ODD8I3vgELFvjrwg5kxSGzHqO1LBs1Q5b0lmXTBDIN9YtI2qhClh47dhSCWNSBbMcO+MQnYNEi+Ku/KhwNuXFj+M8TRiBL0lC/AlkCaKhfRNJGFbL02LEDZs3y748d66tCUQ31//a3sHkz3HGH//dvb4eJE8OvkG3fXgg09ViwAE46CQ4+eOhtUbcs29r8/0UaWpZNNUOmoX4RSROdOik9Stt7UZ7PcvNmf3nggYXr9t8//EC2Ywfss0/9n+f1r4dHHin/uaKukEHhfJZJb1k2VSBThUxE0iQNLUttDOsVtywh2kDW0eEvZ8woXBdFINu+PZyW5UiirpBB4XyWqpAlRIuG+kUkZdSyTAfnhs5bTZ4cbSBraRncTkxyhWwkjaiQBeezVIUsIVpyxoACmYikSBoqZNoYFrq7/f9Vacsyqhmyjg6YNs1vQhsIAllYjaC+Pr/tRVYqZGkY6m+eQGY6ubiIpIsqZOlQfGLxQNQty+J2JfhA1tXl24xhCNYedYUs6m0vYHAgU8syATTULyJpk5YKmXPhVWbSKAhkjZwhKxfIILytL8qFzCg0qmW5ZYt/HlXIEkBD/SKSNmmpkEFzV8mSUCGbPdtfhjVHFlTastCynDKl8PUokCWAhvpFJG3SUiGD5g5kQfAqHeqPcoZsuApZWIEsWHtWhvoDalkmgIb6RSRtVCFLh+EqZLt2wcBAuM/V2+vnoSqtkPX1wbe+Vf3/T5YqZMWBTBWyBNBQv4ikTX8/mA0+mi5pFMiGnyEDf6RimLZs8ZelgWzSJB+eSgPZfffBRRfBww9X9zxZrZApkCVAS87o11C/iKRIX1+yq2NQaKc2cyAr17KM6nyW5TaFDZTbi2zFCn8Z7O5fqaxWyNSyTICWnCpkIpIufX3Jnh8DVcigfMsyeL/Rgaz0KMsgkL36anXP06gKWaO2vQioQpYALTmjXzNkIpIi/f3Jr5AF62vmzWF37PD/DuPHF64LKmRhD/aPFMhmzx5aIVu50l9WG8i2b/dfU1tb9WusRq0ty2p+LlQhSxgFMhFJG1XI0iE4bZJZ4bo4W5ZBM2jXLnj++cGPq1Rw2qTirykKtbQsx4ypbl1TphTeV4UsARTIRCRt+vsVyNJg586hs1ZRB7Jp04betv/+sGePPwoTYNWqwm21tCyjnh+D2ipk1YaqSZMK36cKZAnQYgpkIpIuaRjqVyArH16inCHbd9/yQb10L7KgXbn//rW1LBsRyGqtkFXDrNC2VMsyATTULyJpowpZOuzYMXjLC4h2hqxcuxLKB7LJk2HBgtoqZFEP9ENjKmRQCGSqkCWAWpYikjaqkKVDuQpZlC3LagLZMcf4+w8XyF591bc5S2WpQgYKZImiQCYiaaMKWTqUmyFra/Mb+jYykAW79W/c6Af7g0A2fbp/XLkm0YIF8C//MvT6RlXIatn2op5AppZlAviTi4NT21JEUiINFbJm2xh2YAC+8Y3BQatchczMX9fIQNbW5o8o3LABXnzRr+vYY/39e3r8UZfFOjvhpZdg9eqhn6tRFbIxY/y/aaWnmKo1kAVHWqpClgAt+WNkVSUTkWqZ2QFm9ksze9bMnjazK/LX72tm95vZ6vzl1NE+VzXSVCFrln3InnoKPvYxWLy4cF25GTLw14U5QzYwAK+9Nnwgg8LWF8FAf1Ahg6Fty2AT2XK7+DeyQgaVf/+oQlYjM1trZqvMbLmZLR3mPm/P3/60mT0U1VpyuXwgU4VMRKrXB/ytc+6NwAnAZWZ2BPAp4EHn3KHAg/mPw3vSFFTImq1lGYSX733PXw4M+MpTuWpSe3u4FbKtW/2/cyWBbMUKX6U76qjhA1kwa1YayPbs8W+NqpBB4wJZs1fITnHOzXfOLSy9wcymAN8E/tQ5dyRwflSLaM2pQiYitXHObXTOPZl/fyfwLDAHOAu4PX+324Gzw3zeNFXIshTIvvtdWLiw/MxVEGqWLoUXXii0ARsRyEbaFDZQXCE75BC/B9doFbLSTWPLnQoqKsH3d6WD/Qpk0Xkf8EPn3EsAzrkqT39auRYFMhEJgZnNA44DfgvMcs5tBB/agJnDPOYSM1tqZks7qtgyXRWyePz2t7BsGWzbNvS24lDz/e8Xwku5lmXYM2SVBrKNG2H5ct+uhEIgK/3WKw5kxTNcjTqPJTSuQjZnTmGuL6miDmQO+LmZLTOzS8rc/gZgqpn9Kn+fC8t9klpfzIopkIlIvcxsEnAX8HHnXMXTQc65m5xzC51zC2eM9Nu0hE6dFI8tW/xludmqV1/1/ycLFgwOZEmqkPX2wh/+UAhkwf2Ha1n29Q0On9u3+8ssVcjOPx+eeAJmzar+sY0SdSA70Tl3PHA6fubi5JLbW4EFwJnAu4DPmNkbSj9JrS9mxRTIRKQeZjYGH8budM79MH/1JjObnb99NhBqlV8ty3gEpx4q9/d/R4evOF1wgW9brljhrx8ukIU51F9JIAu2voBCIJs82X8fDdeyhMHhs5EVslqG+msZzB8zxofoJIs0kDnnNuQvNwM/At5Ucpf1wBLn3G7n3KvAw8CxUawlZxrqF5HamJkBtwDPOue+UnTTfwMfyr//IeCeMJ9XLct4BBWycoHs1Vd9IDvvPP/xrbf6y0ZWyIIWZDnB5rDgt7wA36qbPr3yQNbIClmjWpZpEFkgM7OJZtYevA+cBvxvyd3uAd5qZq1mNgF4M35YNnQa6heROpwIfBA4NX9U+HIzOwO4Bninma0G3pn/ODSqkMUjqJAN17KcPh0OOggWLYIHHvDXD7ftxc6d5Q8OqEVHhw9J48YNf58gkE2aBPPmFa4PNocttnGjH/yH+CtkUbcs0yDKH/VZwICR1ygAACAASURBVI/8H5a0Av/lnFtiZpcCOOcWO+eeNbMlwEpgALjZOVca2kKRUyATkRo55/4HsGFufkdUz9vXN/Iv3yTI4sawo1XIjjzSvx/MJUH5atLkyf7/cM8eGD++/nWNtClsIGhZHn20P1NAoFyFbMMGOOUUeP75wV9rI4+yVIWsILIKmXNujXPu2Pzbkc65q/PXL3bOLS6637XOuSOcc0c5574a1XrGtPjX0t5+BTIRSYc0VciytDFsJS1L8IEsMFzLEsKbI6skkI0b5ytjb3nL4OtLz2fZ3e0rgUcf7T+Oq2WpCllB3NteNMy+E/2fma/tKnMWVRGRBNIMWeN1dRVOtl3asizdKX/ePN+2hOFblhDeHFklgQzgscfg858ffF1pheyVV/zlAQfAtGlDW5bjxjWmOqsKWUHTBLJZk/131uadCmQikg5pqpBlJZAF1TEYWiHbutWHsuKh+k9+Et797vIhIa5ANmsWTJgw+Lrp0/3XFvw/BQP9++/vP2dphaxR+3WpQlbQPIGs3TfwN+3ojnklIiKVUYWs8YJAZja0QhZUmIoD2Z//Ofz0p+U/VxBqwghkzlUeyMqZPt2HyeCAhWAPstmzYebMoRWyRgz0w9BtL1atghNPHDrvFlAgy4ApE8YwtiXHph2qkIlIOqhC1nhBYJk3b2iFrFwgG0lwup7bb/czW/XYscOHkXoCGRS+hqBCFgSy4q+1kRWy0pbld78Ljz5aOFdoKQWyDDAzZrSPY7MqZCKSEqqQNV5QITvsMB9eik8pVG0gO+44+NjH4JZb/KakTz1V+7oq2RR2JKW79W/c6P/vZsxIRoUsaFk+/LC//P73y99fgSwjZk0ex6adCmQikg6qkDVecSArPaVQtaHIDL72NViyxH+eN70Jrr++tnXVG8hKK2QbNsB++/mtMWbM8AcrBFWquCpk3d3w+ON+D7WHHioceFBMgSwjZk0ez2a1LEUkJdJQIcvaPmRBy/Kww/xlcSsvCDPTplX3Od/1Lj8bdcop8Ld/Cz091a8r7EC2cWNhz7KZMwfftmNHPEP9Tzzhj3D953/2M3M//OHQ+yuQZcTM9nEa6heR1NDJxRtvyxb/NQU72JcGsgkThh7BWIl994UPfMD/O73wQvWPrzeQBSEy+DzlAlnQtmxky7K4Qha0Ky+5BI44YugcmXP+fgpkGTBz8nh2dPfR1ZORVw4RybQ0tSyzsjHs1q1+GL80pMDgTWFrceih/nL16uofW28gC4JkcYUsOM1S8LV2dPjQE9e2Fw8/7Deq3Xdfv+nuww8PblsGByLUcnLxNGiqQDZrst/6YrPmyEQkBdLQssxihWzffQvBp7hC1tERbyCrtToXCHbr7+nxn69chayry/9fNnqov7sbfv1rOPlk//H55/tweNdd/uOBAfjQh6CtDd7znsasrdGaLJBpc1gRSY80VciyFMimTi0EstIKWa0VKvBtwylTag9k9Tw3FHbr37TJfxwEsuKvtZGnTYJC+/GJJ2D3bnjrW/3HRx7p25bB0Zb/+q/+RO7XXQeHH96YtTVaUwWymdocVkRSRBWyxtu61VfIxo71VaLSGbJ6KmRmvkoWZyDr6Bi8Bxn4ANrS4gNZcN7NRlfIfvELfxkEMoA/+zPftrzvPvinf4Jzz/XzZVnVVIEsqJBpc1gRSQNVyBovaFmCD0BhBjKIP5C9+urg0yZBYeuLOCtkzzwDr399YU1QaFuec47fouPf/92H2qxqqkC2T9sYxrbmtDmsiKSCKmSNF7QsYfCGqT09vnoURiB76aXqd+4PM5AVnzYpEOzWH1eFDAZXx8C3LI84ws+P3XlnIShnVcL/9gqXmfnNYRXIRCQFVCFrrP5+XyEqrpCtWePfr3aX/uEceqiv+qxZ48NGJZzzwTAYvq/VjBn+vJovvugrTcWfL6iQBYGs0RUyKAz0F7vxRj/zVu62rGmqChn4OTIN9YtI0g0M+F/ESa+QZWlj2O3b/b95uZZlEMjqrVIFR1r+/veVP2bXLl9RmzWrvucOwuSqVf5zFYf9oBrY6JZl8RrKha6TT/aty2bQdIFMFTIRSYMg4CS9QpbL/xbJQiALTptU3LLs6PDhOMwKGVQ3RxYcFRlWIFu5cnC7EgqBLK6W5Zw5cNBBjXnOpGq6QDazXadPEpHkCzZaTXqFzMyHsixsDBucNqm4Qtbf789DGVYgmzrVf45aAlm9Lctg7evXlw9kO3cWnqu9vb7nqlTQsnzrW7M9sF+JhP/tFb5Zk8ezc08fnT19TBjbdF++iKREEHCSXiEDHxqzVCELAlnxDvZhBTKo/kjLsCtkMDSQBa3Y55+HiRMb932Xy8FHPwoXXNCY50uyFPyoh2tme35z2B17mDe96b58EUmJtLQsIXuBLGhZFm+YGsyShXGk36GHwoMPVn7/4EjPegNZ8fxb8fYSUAifq1c3bn4MfFXsG99o3PMlWdO1LIPTJ2mOTESSLC0tS8hOICvXsoRChWzKlHBObH3oofDyy9DZWdn9gwpZvdW54jBZrmUJ8Ic/NG5+TAZrwkCW3xxWR1qKSIKpQtZ45Yb6wVeo6j1tUrFgsP8Pfyhc19sLt9wCe8r8atq0yZ92qd4w2Npa+NqGC2Q7dza2QiYFTRfIZgYnGFeFTEQSTBWyxtu61c9PjR3rPw4qUkGFLIz5MSh/pOWdd8LFF8OSJUPvv3lz/e3KQPA1DBfIQIEsLk0XyCaPb2Vca057kYlIoqlC1njFp02CweezjDqQ/fu/+8uXXhp6/02b6j/CMhB8DaUzZJMmwTjfQFLLMiZNF8j8bv3jNUMmIomWpgpZa2s2AxkU9ufq6AgvkLW3+4pXEMiefhoefdS/v3790Ptv2hRehSxou5Z+vuKd+1Uhi0fTBTLQ5rAiknyqkDXe1q2FGatAsFt/mBUyGLz1xc03+/mw6dNh3bqh9w2zZTlnjn8L2rLFgkCmClk8mjKQzZyszWFFJNnSVCFracnGxrDlKmQzZsALL/hh+7CG+qEQyLq74Y474Jxz/LktSytk3d3+dEZhtSyvugp+9rPyt6lCFq/mDGTtqpCJSLKpQtZ4W7YMrZDNnAlr1/r3w66QvfKKD2NbtsBHPgIHHDC0QhbWHmSBmTPhyCPL3xYETlXI4tGUgWzW5PHs7uln154M/EknIpmUtgpZ0gPZY4/5HeGdG/4+W7eWr5AFjwk7kIGvWB10EJx6Ksyd6/cnGxgo3C+sXforoQpZvJo0kAW79atKJiLJpApZuG64AW68EdasKX97V5dvD5Yb6g9EEcg2bvTbXeRyvkLW21uoikHh/bBaliNRIItXcway9mC3fs2RiUgyqUIWnoEBeOAB//6TT5a/T+mmsIHiubEwA9nrX+8vW1rgoov8+3Pn+sviObI4KmRqWcajKQPZzKBCtlMVMhFJJp1cPDwrVhTORblsWfn7lJ42KVAcyMIc6p84EQ45BM46q7BJ6wEH+MviObIgkDWiQnbwwf5yzpzon0uGSsGPevgKu/WrQiYiyaSWZXjuv99fHnDA6BWy4VqWLS3hV45+9avB7cFyFbLNm/2mrRMmhPvc5Zx0Ejz3HBx2WPTPJUM1ZYWsfVwrbWNadKSliCRWmlqWSd8Y9v774aij4F3v8hWycoP9QYVsuJbl9Ol+89QwzZ07OJDNmOH3ByutkDWiXQn+61MYi09TBjK/W/84nWBcRBJLFbJwdHXBI4/AO98Jxx/vK2HlTk80XIUsmBsLc35sOGY+pJXOkDUqkEm8mjKQAcxsH8+m7aqQiUgypalCluSNYR95xG/qetppsGCBv67cHNlwgWzsWJgypTGBDHxbtbRl2Yj5MYlf0wayufu2sfa13XEvQ0SkLFXIwvHzn/tQdfLJcPTRfq3lAtnWrf629vaht73udf6tEebOja9lKfFKwY96NA6b1c4Pn3yZ7Z297DNhTNzLEREZJG0VsqQGsvvv98PqwVD8kUeWH+wPdukvNyd2993+qMhGOOCAwuawAwP+HJoKZM2haStkb5jl/wz6/eadMa9ERGQoVcjq98orsHKlnx8LHH98+cH+cuexDBx0UOPahnPnFjaHffVVv04FsubQtIHs0FmTAPjdKwpkIpI8qpDVL9gM9rTTCtctWOD3JHv55cH33bp16BGWcQj2Ilu/vrG79Ev8mjaQzZnSxsSxLazepEAmIsmjCln9fv5zP4w/f37huuOP95elc2QjVcgaKdiLbN26xu7SL/Fr2kBmZhw6q53fKZCJSAKpQlYf5/z82B//sT9PZODYY/3HpXNkSQlkxRUyBbLm0rSBDPxg/+pNu+JehojIEGk6dVISN4Zds8bPkJ1yyuDrJ06Eww8fWiFLSsty+nQYN85XyNSybC5NHcgOnTWJ13b38OoubRArIsmilmV9NmzwlwcdNPS2BQsGV8j6+2HbtmRUyIo3h920yW/ZoZN9N4emDmSH7Zc/0lJtSxFJmLS1LJO2MexI7b7jj4eNG/0bwPbtvsWZhEAGhb3Igj3Iwj5lkyRTpIHMzNaa2SozW25mS0e43yIz6zez86JcT6lg6wu1LUUkaVQhq89IgSzYsf/JJ32r8qtf9R8nJZAFu/Vrl/7m0ogf9VOcc68Od6OZtQBfBH7WgLUMMrN9HJPHt2qwX0QSJ20VsqQFslde8cP75U55NH++rzp95jOwejXs2uVPPH7WWY1fZzlz5/ptOaZMgf33j3s10ihJaFleDtwFbG70E5sZh+3Xrq0vRCRxVCGrz6ZNPoyVC7Tt7f40SitX+hC2fDksWQKTJzd+neUccIDfHPbZZ3WEZTOJ+kfdAT83Mwf8m3PupuIbzWwOcA5wKrBouE9iZpcAlwC8LuQTih06q50fr9yIcw5To15EEkIVsvqMdg7In/zEX86Z05j1VCPYi2zPHrUsm0nUFbITnXPHA6cDl5nZySW3fxW40jk34o+yc+4m59xC59zCGTNmhLrAw2a1s72rl807daSliCSHKmT1GS2QzZmTzDAGhb3IQBWyZhJpIHPObchfbgZ+BLyp5C4Lge+Y2VrgPOCbZnZ2lGsqFZxCSUdaikiSpKlClsR9yDZtgv32i3sVtQkqZKBA1kwiC2RmNtHM2oP3gdOA/y2+j3PuIOfcPOfcPOAHwEedc3dHtaZyDssfaalzWopIkgQBJ5eESd9RJK1C5tzoFbIkCzaHBbUsm0mUP+qzgP8xsxXA48CPnXNLzOxSM7s0wuetyrRJ45g2cay2vhCRROnr80EnDaOtSQtku3ZBV1d6A1mwOSyk92uQ6kU2neCcWwMcW+b6xcPc/8NRrWU0h86axO83q0ImIsnR35+O+TFI3sawr7ziL9McZg44AJ5/Pt1fg1QnBcXw6AXntHTOxb0UERGgUCFLg6RVyLJwUu65c327etq0uFcijZKSv7+ideisdnbt6WPD9m7mTGmLezkiIvT1patCpkAWrrPP9v//aQnlUj9VyCg6p6UG+0UkIdLWslQgC9d73gO33Rb3KqSRFMiAN8z0gWzl+u0xr0RExEtby3JgwB/dmASbNvnB+JC3rRSJlAIZsM+EMSw4cCpLnn4l7qWIiADpq5CBD2VJEJw2KS3/fiKgQLbXmUfP5tmNO3i+Q9tfiEj80lQhC4JPUtqWad6DTJqXAlneGUfPBuDHKzfGvBIRkXRWyJISyF55RYFM0keBLG+/fcazaN5UBTIRSYQ0VciSFshUIZM0UiArcubRs/ndpp2sLjmvZcfOPWza0R3TqkSkGaWxQpaUzWEVyCSNFMiKnH70bMzgx6sKVbId3b2ce+Ov+dCtj8e4MhFpNu97H/zd38W9isokqUK2axd0diqQSfookBWZNXk8i+btu7dt6ZzjH+9axbotXTz3ytDKmYhIVP70T+Hii+NeRWWSFMiCPcj22y/edYhUS4GsxP85ZjarN+/i95t28u3H1/HjVRu56MR5mMFPVmlbDBGRUkkMZKqQSdookJV491H7kTO4/oHVfO7ep3nrodP5zJlHsPDAqfxklQb+RURKJSmQZeHE4tKcFMhKzGwfz5sPmsaPV238/9u787iqq/yP46/PZVNcUAERFxTccN9NU3PNtLKmMtNya7FpnZzm1zTTMs00bTOVbTOllZatlpbtNu5bioKKuyKiIm4gioCICJzfH/eCbOpluXyB+3k+Hjy4fO+533sO3+vxzfl+v+dQr5YXM8Z1x2YTrndc8B+bqPOUKaVUQVUpkOkImaquNJCV4JYezbAJvHlHdwLr+QD2kTOARTpKppRShVSliWHzApkum6SqGw1kJRjbqzkRfx3OwLYB+duC/WrTq2XDQndgKqWUqnojZP7+4OVldU2UKh0NZCWw2YTG9WsV2359l2D2HE8jTpdXUkqpfFVpHjKdg0xVVxrISmF03mnLHXq3pVJK5alqI2Q65YWqjjSQlULTBrXpEdJAl1dSSqkCqlog0xEyVR1pICulG7oEs+tYKgdPnrW6KkopVSVUpUCmC4ur6koDWSnl3W35ffRRi2uilFJVQ1UJZGfP2r80kKnqSANZKTVv6MvANgHMi4wnOyfX6uoopZTlqkog0znIVHWmgawMJvYL4diZTJbvSbS6KkopZTkNZEqVnwayMhjRIYig+j58tiHe6qoopZTlqsrEsLqwuKrONJCVgaeHjfF9Qlgdk0R8cobV1VFKKUvpCJlS5aeBrIwm9A3BwyZ8vvGQ1VVRSilLVZWJYfMCWePG1tZDqbLQQFZGTfxqMaJDY+ZHJXA+uwrc662UUhapKiNkx49Do0a6bJKqnjSQlcOkfq04dTaLRduPk5trWLE3kXs/jmTGkhirq6aUUpWmqgQynRRWVWeeVlegOru6tT+hAXV4c2kMby3bx4GTZxGBiLhkHhnaBm/P4nnXGIOIWFBbpVRZicgc4EYg0RjT2bHt78A0IMlR7CljzC/W1NBaVSGQZWXB3r0ayFT1pSNk5WCzCVP6t+RgcgYNfL14a3x33r2zJ2ezcth44FSx8j9tO0qfF5dy+JTeCKBUNfMxMKqE7W8YY7o7vtwyjIH1gezsWRgzBnbuhIkTramDUuWlI2TlNOXqVozoGETzhr4AZGRl4+1pY/meRAa2DShU9osN8ZxMz+Kphdv55J6+OlKmVDVhjFktIq2srkdVVdpAduIEiFTMxffJyXDDDRAZCbNnwz33lH+fSllBR8jKSUTywxiAr7cnV7f2Z9meExhj8rcnpmayPi6Zto3rsmbfSRZsSrCiukqpivWIiGwTkTki0vBShUTkfhGJEpGopKSkSxWrtkoTyLKyYOBAmDy5/O975Ahccw1s2QILFmgYU9WbBjIXGBbemEPJGcQVWID85+3HMAbevasnfVs14p8/7SIxLdPCWiqlyuk9oDXQHTgGvH6pgsaY940xvY0xvQMDAyurfpWmNBPDzpoFsbGwa1f53jMmBgYMgPh4+PVXuOWW8u1PKatpIHOBoe3t4/ArCiyt9MPWo3QIrk/boHq8fFsXMrNzee77nVZVUSlVTsaYE8aYHGNMLvAB0NfqOlnF2RGy1FR4/nn744QE+2hZWWzZYh9ly8iAlSth6NCy7UepqkQDmQu0aORLu6C6LNttD2SHT2WwJT6FMd2CAWgdWJfpI9qyaMdxFm0/ZmVVlVJlJCLBBX68BdhhVV2s5uzEsK+9BidPwiOPgDFwqAzzaq9cCYMHQ+3asHYt9OpV+n0oVRVpIHORYeFBRB48RWrmBX7cdhSAMV2b5j8/bVAYHYPr88LPu8nKzrWqmkopJ4jIl8B6oL2IJIjIvcC/RWS7iGwDhgJ/tLSSFnJmhOzYMXj9dRg3Du64w74tLq5073P0KIweDS1awG+/Qbt2ZauvUlWRBjIXGd6hMdm5hjUxJ/lx6zF6hjSgRaOLF/97edh4YlR7jqSc49vNeoG/UlWZMWaCMSbYGONljGlujJltjJlkjOlijOlqjLnJGOO2w93OBLJ//MN+ivLFFyE01L7twIHSvc/8+ZCZCd98A82bl62uSlVVGshcpEeLBvjV9uLDtXHsPpbKmG5Ni5UZ0i6Qbs39+M+KWB0lU0pVW1cKZHv3wocfwgMPQJs2EBwMPj6lHyGbPx+6doXw8PLVV6mqSAOZi3h62BjSPpAt8SnYBG7oGlysjIgwfUQ7Ek7rKJlSqvq6UiCbO9c+79izz9p/ttnso2SlCWQJCfbTlOPGla+uSlVVGshcaFi4/W7LfmH+NK5Xq8QyQ9pfHCW7kKOjZEqp6udKgWzxYujfv/BEsKGhpTtl+c039u+33162OipV1Wkgc6Eh7RoTUNebu65qeckyzo6SbYk/ze5jqa6oplJKlcvl5iE7eRI2b4Zrry28PSys5BGy3Fw4fbr49q+/hm7d9EJ+VXNpIHMhP18vop65tsTTlQUNaR9I1+Z+vLO85FGyTyMOcdt76xj73jp2HDnjquoqpVSZXG6EbNky+xQXI0cW3h4WBikpxcPX7Nn2a8w2bbq4LSEB1q3T0TFVs2kgqwLso2RtSTh9jilzNrIhLhmAnFzDCz/t4tnvdjC4XSANfL2Z+tFGDhZYAUAppax2uUC2ZAk0aAC9exfennenZdFRspUr4fx5mDAB0tPt2xYssH/XQKZqMg1kVcTQ9o159saOxJxI4473Ixg3cz33zY3kw7UHmHp1Kz6c0odP7u1LTq5h8pyNuuySUqrKuNTEsMbYrx8bPvximTxhYfbvRa8ji4y0n5bcvx8efdS+bf58PV2paj4NZFWEiHDvwFDW/HkYfx/TkcOnM1gVk8RzYzry95s64WETWgfWZc7UPiSlnWfqnEjSMi+UuK8LObnk5JoSn1NKqYp2qRGymBg4fLj49WNQ8ghZSgrs2wdTpsBTT8HHH9tn91+3Tu+uVDWfpyt3LiIHgTQgB8g2xvQu8vxdwJOOH9OBB40xW11Zp6qutrcHUweEcudVLUlMy6R5Q99Cz/cIach7E3ty98eRvLdyP38eVXhCntxcw+0z13PszDmmDQrjzqtC8PV26WG2jDGGTYdO0yOkIR42sbo6SrktEftX0UC2eLH9e0mBrH59CAgoHMiiouzf+/Sxr0+5bBk88YR9m56uVDVdZYyQDTXGdC8axhwOAIONMV2BfwLvV0J9qgVvT1uxMJZnSPvGjO7chE/XHyK1yCjZ0t0niD6cQl0fT174eTcDXlnO28v2cT77Cqv+lmDv8TTeXBrD0l0nOHOu5NE4K30XfYSxM9fz1rJ9VldFKbfn4VE8kC1ZAq1bXzw9WVTRqS8iI+3fe/e237n5xRfg5wfdu0Pbtq6pt1JVhaVDJ8aYdQV+jAB0MQwnPTSkDb9sP85nEYd4aEgbwD5i9PbyfbT09+V/069ha8IZ3l0Ry4wlMZzOyOK5MZ2c3n9sYjrj31/P6Qx7EBOBTk3r86dr2zM0vHGx8hFxySzcfITp17Yl2K92xTTyCj5eZ1+Z+L8rYhkW3pjuLRpUyvsqpYorGsguXIAVK2DixEu/Jiys8N2UkZH2mfwbNrT/3KoVrFljn9VfqZrO1SNkBlgsIptE5P4rlL0XWFTSEyJyv4hEiUhUUlJShVeyOurczI9BbQOYs/YAmRfsveCKvYnsOJLKw0Pa4Olho1fLhsye2ofJ/Vvy8bqDbIkvYXKfEhw7c47JszfgYbOx+I/XMO/+fjw2vC2p57J55rsdJV6f9vKiPXwVdZiRb6zmm00JGOPaa9iiD6ew9XAK/zeyHUH1fHj862jOZZV+FFApVTGKBrKICPtdkkWnuygoLAwOHbr4ushI++nKgrp00Yv5lXtwdSAbYIzpCYwGHhaRa0oqJCJDsQeyJ0t63hjzvjGmtzGmd2BgoOtqW808NKQNJ9OzmB912D46tiyWZg1qc0vPZoXKPXFde5rUr8Vfvtl+xTUzUzKymDx7I2mZ2Xx8dx/aBdWjX5g/00e046nrwzmSco4VexILvWbHkTNsPZzCtEGhhDepx5/mb+X+TzeRlHa+wtuc55N1B6nr48nUAaG8ens34pLO8q9f97js/ZRSl+fpWTiQLV5sXyJp6NBLvyY01D6SduQIHD9un2+saCBTyl249JSlMeao43uiiCwE+gKrC5YRka7Ah8BoY0yyK+tT0/QLa0SPkAbMWh1H84a+RB9O4aVbuuDlUThn16vlxQu/68y9c6OYtWo/jw63X4yRlZ3Lwi0J7E86S06uISfXsPHAKQ6dymDu3X3p3Myv0H5GdAgiqL4Pn204xIiOQfnbP98QTy0vG48Ma0tdH0/mrD3Aq4v3cses9cx/oD/+dSv2fMPJ9PP8tO0YE/q2oK6PJwPaBDD16lZ8vO4gIzoEMbBtQIW+n1LqyoqOkC1ZAn372ucgu5S8a8vi4iAtzf5YA5lyVy4LZCJSB7AZY9Icj0cCzxcpEwJ8C0wyxsS4qi41lYjw0JA2TPskisfmbSHYrxa39WpWYtnhHYK4sWsw7yyP5brOTYg+nMJbS/dxJOUctbxseNpsiEAdb0/emdCD/q39i+3D08PG+D4hvL18H/HJGYT4+5KWeYHvo49wU7em+NX2AmDaNWF0D2nAxA83MPWjSL68vx91fSruozZvYzxZOblM6t8qf9uTo8JZvS+JibM34OvtgX9db/zr+PDgkNZc16lJhb13VXQ+O4cNcacY1DYAEb3bVFmjYCA7fdp++vHppy//moKB7OBB+4hajx4uraZSVZYrT1kGAWtFZCuwEfjZGPOriDwgIg84yvwN8AfeFZFoEYlyYX1qpOHhjWkXVJfUzGweHNIaH0+PS5Z9bkwnant7cP1ba/jzgm00quPN3Hv6svv5Uez4x3Vs//t1RDw1/LIBZkLfEGwifL7RfkH9d9FHycjKKbZeZ59WjXj3rp7sOpbK/Z9E5V/nVhJjjNPXnGXn5PJZRDyD2gbQpnHd/O21vT345J6+PHFdeyb0DaFXSEPOnLvA419FJjFlkAAAEh9JREFUE5+c4dS+q6vZaw8wec5G1u/XAWZlHQ+PixPDrl5tX5NyxIjLv6ZFC/vr4uLsAa5TJ6hTx/V1VaoqclkgM8bEGWO6Ob46GWNedGyfaYyZ6Xh8nzGmoWNajEtNjaEuw2YTnrq+A4PbBTKud4vLlg2s58Mrt3ahZ0hDZk7sxQ+PDGBwu8BSjao08avFiA6NmR+VQOaFHD6POETnZvXp2tyvWNnhHYJ4dWxX1u1PZvq86GKhzBjDL9uP0e/lZTz3w06n3n/xrhMcT81kcoHRsTzNG/ry8NA2PHtjR94c34PP77sKmwj/N39rjZ0o1xjDgk32Rek/WX/I4tood1ZwhGz5cqhVC6666vKv8fSEkJCLgazo8kpKuROdqb8GGNK+MXPv6Ustr0uPjuUZ3SWYrx/oz6jOTcp8emtiv5acOpvFiz/vZs/xNCZe1fKS+7q1Z3OevbEjv+48Tv+Xl/HvX/dwNOWcfeLaTzbx0OebOZeVw6cRh9h59PILpx9NOcd/V8TSvGFthpUw9UZRTRvU5rmbOrHx4CnmrD1wxfJlEXMijdveW8d7K/eTkpFV5v2kn8/mujdW83XU4VK9LvpwCnFJZ2nl78viXcc5knKuzHUoj5Pp5/NvLlHuqWAgW7ECBg50brqKsDD7+pXJyXr9mHJvGshUqQ1oHUArf18+jThEPR9PxnRretny9w4MZd79/egb2oiZq/Yz6N8rGPbaKtbGJvH09R1Y9cRQGtT24qVfdpf4H3rmhRzeXraP4a+vIjYxnSdHhTs9M/9tPZsxsmMQry7eS8yJtDK193L+tWgPWw+n8K9f99Dv5WX89dvt7E9KL/V+Plp7gL0n0nh/dVypQs2CTQnU8rIxc1IvAL7YYM0o2X+Wx/LEgm38tO2YJe+vrJcXyJKSYPv2y99dWVBoKBxzfGw0kCl3poFMlZrNJvnXjN3Ssxl1nLhgv1+YP7Mm9Wb1n4dy36BQru8SzOLpg5l2TRgN63jz2PC2/BabzIq9hafUWLvvJMNfX8WMJTEMC2/M0scHXzEAFiQivHRrF+r5eDJ9XjQ/bTvKutiT7Dqaytnz2VfewWVEH05h2Z5E/nhtOxY9NoibuzXjm80JjH5rDZ9FHHI6WKVkZPH+mjga+HoRm5jO5vgUp16XeSGHH7ceZVSnJoQ3qc+w8CDmbTxcplUZyiMrO5fvo48A8PIvu3U+ODeVF8hWrrT/7Gwgy7uw39sbunZ1SdWUqhY0kKkyGdenBTd3b8q0QZdYE+USmjf05a+jO/D6uG6E+F9cGurOq1oSGlCHl37ZQ3aOfa60TyMOMeWjjfh6e/DltH78966etGhU8nJSlxNQ14eXb+1CzIk0HvliC3d+uIHr317D4FdXsPd48VGzyIOnuOvDCJ5auJ3vo49wIjWzxP3OWBJDozreTLm6FR2C6/OvsV357clh9Avz55nvdvCHedGXXAC+oFmr40g/n83sKb2p7eXB15HFT1ueOptV7HTk0t0nSM3MZmwv+7WDU65uSfLZLH7ZXrmjVCv2JnI64wIPDmnN0TOZzFy1v1LfX1UNeYFsxQqoW9f568HyAlm3bvZQppS70kCmysSvthdvje9RpoBUEm9PG38ZHU5sYjpfbIzn+R938ex3OxjcLpCFDw8ocRqO0hjZqQlRz4zIX3ngnQk98LAJd34QUehU5rLdJ5j44QZiTqTzQ/RRHpsXzVUvLWPse+tITLsYzKIOnmJ1TBK/vyas0JQegfV8+HhqH564rj0/bzvKTf/5jX2XOVWamJbJR78d4KZuTenVshE3dA3mp21HC43enc/O4Y5Z6xk5YxWbDp3K375gUwLBfrXyfzcDWgcQFlCn0i/u/2ZTAoH1fPjTte24sWswM1ftJ+F0zb6zVRWXNzHs8uUwaBB4eTn3utBQ+3c9XancnQYyVWWM7BhE39BG/O37ncz57QD3DAjlg8m9K2wOswa+3vkrD4zp1pQvpvXLD2X7TqSxcEsC93+6ifZN6tnXAn1uJD89OpC/jA5n59FUbntvHQdOngXgjaUxBNT1ZlL/lsXex2YTHh7ahi+n9SP9fDZ3friBg47XFfXuiv1cyDH8cYR9bZg7+rTgbFYOPxe4FmvWqjj2Jabj6+PJlDmRbI4/TWJqJqtjkri1Z7P86+lsNmFiv5ZsiU9hW0IKEXHJPLlgGz3/uYQx76xlxuK9bI4/fck7TrOyc/n7DztZFeP88mTJ6edZvieR33VviqeHjaeu74CIfSkt5V48POwz7e/dC8OGOf+68HBo2hRuvNF1dVOqOpDqdldU7969TVSUTldWU+04cob75kbx0NDWJU5tUdFiE9OZ8EEE5y/kkJqZzdWt/Xm/hBC49XAK93wciQEeGtKaF37ezTM3dOC+K5yy3XcijXGz1uPr7ck3D15NE79a+c8lnM5g6GsrGdurOS/far94xhjD8BmraOTrzYIHr2Z/Ujqj31zDyE5BPHNDR8a/v57k9CxGdAxi4ZYjLP/TYMICL87HdubcBfq/vIzsHENWTi6+3h4M7xDEsZRzbI4/Ta6BZg1q89Xv+9G8YeHRzf+uiOXV/+1FBB4d1pbHhre94s0TH/12gH/8uItfpw8ivEl9AN5auo83lsYwY1w3gv1qk5mdw/kLOZw9n0NGVjbpju9/GN622KoSlyIim2rKtDg1tQ/r0QO2bbPPPxYVBb16WV0jpaoGZ/svDWTK7cUmpjNp9gZ6hjTk9XHdLjl9yMGTZ5k8ZyPxpzJoXM+H1X8e6tRUI9sSUrjzgw008avF17/vjzGGH7Ye5fMN8cQnZ7DyiSE0bVA7v/zMVft5ZdEelj5+DU8v3MHuY6ks/dNgGterxbEz57hjVgTxpzLoGdKAbx8aUOz9PlgdR0RcMmO6NWVkpyB8ve3hMiUji1UxSTy9cAcdm9bnS8cIIcDhUxlc+8YqBrYJpIGvFws2JTCobQBvje9BozreGGPIyMqhtpcHtgIh7cZ31gDw06OD8redy8phxIxVl52CQwSinx2Jn69z57U0kFV9vXvDpk32pZJOnrSPmCmlNJApVSo5ucapqTSS0s7z9MLt3NKjGaO7BDu9/4i4ZKbM2UgDXy+S07PIzjV0blafR4a2YVTnwvtJTMuk/8vLCQuow77EdF65tQvj+4bkP38k5RyPfxXN7weHMSw8qOhbXdGCTQn83/ytPDkqnAeHtAbgvrmRrNufzNLHBxPsV4t5kYd57vudeHoIHiKkZ2VjDLT09+WVW7vSv7U/e46nMurNNTw3piN3Dwgt9B7J6efZlnAGHy8btbw8qOXpQR0fD+r4eFLH25NaXrZSzYOngazqu+oq2LgRbr4ZvvvO6tooVXU423+5dHFxpaoLZ+c1C6znw/uTS58L+oX5M3NiL15ZtIebuzfjtp7Nad+kXollG9erxbDwxizZdYK+rRoVW4HBfsqxf6nrkOe2ns1YvucEM5bsZVDbAI6mnGPp7kSeuj48f6RuQt8QOjf1Y15kPN6eNur5eOLj5cFXkYeZ8EEEk/q1JNcYPG3CTSVMQ+Jf14ehTkzeq2qOvBExZ6e7UEoVpoFMqUoyNLyx0yHlngGh7Dxyhpdu7VLoFGFFEBFe/F0Xog6eZvpX0ZzLyqF9UL1io1xdmvvRpXmXQtvuHtCK1/4Xw0frDmAMXNsxCP+6TkzHrmq8vEBWmgv6lVIX6V2WSlVB/Vv7s+6vwwstoF6RGtbx5rXbuxGbmM6RlHO8cEtnpy6w9/X25G9jOjL/9/0Z1DYg/5SnUh4eEBBgXyBcKVV6OkKmlJu6pl0gf7uxI5nZOfRp1ahUr+3dqhGf3nuFlaOVW7nrLsjMBJv+ma9UmWggU8qN3TMw9MqFlHLCtGlW10Cp6k3/llFKKaWUspgGMqWUUkopi2kgU0oppZSymAYypZRSSimLaSBTSimllLKYBjKllFJKKYtpIFNKKaWUspgGMqWUUkopi2kgU0oppZSymAYypZRSSimLaSBTSimllLKYBjKllFJKKYtpIFNKKaWUspgGMqWUUkopi2kgU0oppZSymAYypZRSSimLaSBTSimllLKYBjKllFJKKYuJMcbqOpSKiCQBhy5TJAA4WUnVsZq7tNVd2gnu09bStrOlMSbQVZWpTFfow9zl+IO2tSZyl3ZC6drqVP9V7QLZlYhIlDGmt9X1qAzu0lZ3aSe4T1vdpZ2l5U6/F21rzeMu7QTXtFVPWSqllFJKWUwDmVJKKaWUxWpiIHvf6gpUIndpq7u0E9ynre7SztJyp9+LtrXmcZd2ggvaWuOuIVNKKaWUqm5q4giZUkoppVS1ooFMKaWUUspi1TaQicgoEdkrIrEi8pcSnvcRka8cz28QkVaVX8vyc6KdU0UkSUSiHV/3WVHP8hKROSKSKCI7LvG8iMjbjt/DNhHpWdl1rChOtHWIiJwpcEz/Vtl1rAgi0kJEVojIbhHZKSKPlVCmxhzX0nCX/gu0DyvwfI34rGv/VahMxR5TY0y1+wI8gP1AGOANbAU6FinzEDDT8Xg88JXV9XZRO6cC/7G6rhXQ1muAnsCOSzx/PbAIEKAfsMHqOruwrUOAn6yuZwW0Mxjo6XhcD4gp4fNbY45rKX4vbtF/laKt2odVoy/tv1x3TKvrCFlfINYYE2eMyQLmATcXKXMzMNfxeAEwXESkEutYEZxpZ41gjFkNnLpMkZuBT4xdBNBARIIrp3YVy4m21gjGmGPGmM2Ox2nAbqBZkWI15riWgrv0X6B9WEE14rOu/VchFXpMq2sgawYcLvBzAsV/UflljDHZwBnAv1JqV3GcaSfAbY7h0gUi0qJyqlbpnP1d1BT9RWSriCwSkU5WV6a8HKfcegAbijzlbscV3Kf/Au3DCnKnz7r2X2VQXQNZSX8pFp2/w5kyVZ0zbfgRaGWM6Qos5eJf1TVNTTieztqMfe2zbsA7wHcW16dcRKQu8A0w3RiTWvTpEl5SU49rHnfpv0D7sIJqyjG9Eu2/yqi6BrIEoOBfUc2Bo5cqIyKegB/Vb5j1iu00xiQbY847fvwA6FVJdatszhzzGsEYk2qMSXc8/gXwEpEAi6tVJiLihb0z+9wY820JRdzmuBbgLv0XaB9WkFt81rX/Kvsxra6BLBJoKyKhIuKN/aLXH4qU+QGY4ng8FlhuHFfhVSNXbGeR89U3YT/PXRP9AEx23NXSDzhjjDlmdaVcQUSa5F0vJCJ9sf87Tba2VqXnaMNsYLcxZsYlirnNcS3AXfov0D6sILf4rGv/VfZj6lnWF1rJGJMtIo8A/8N+F88cY8xOEXkeiDLG/ID9F/mpiMRi/8tyvHU1Lhsn2/kHEbkJyMbezqmWVbgcRORL7HfnBIhIAvAc4AVgjJkJ/IL9jpZYIAO425qalp8TbR0LPCgi2cA5YHw1/c94ADAJ2C4i0Y5tTwEhUPOOq7Pcpf8C7cOogX2Y9l+u67906SSllFJKKYtV11OWSimllFI1hgYypZRSSimLaSBTSimllLKYBjKllFJKKYtpIFNKKaWUspgGMlVjiMgQEfnJ6noopVRZaB/m3jSQKaWUUkpZTAOZqnQiMlFENopItIjMEhEPEUkXkddFZLOILBORQEfZ7iIS4Vh4eKGINHRsbyMiSx0L2G4WkdaO3dd1LFC8R0Q+z5sxWimlKor2YcoVNJCpSiUiHYA7gAHGmO5ADnAXUAfYbIzpCazCPvszwCfAk46Fh7cX2P458F/HArZXA3nLVfQApgMdgTDssy0rpVSF0D5MuUq1XDpJVWvDsS8eHOn4w682kAjkAl85ynwGfCsifkADY8wqx/a5wHwRqQc0M8YsBDDGZAI49rfRGJPg+DkaaAWsdX2zlFJuQvsw5RIayFRlE2CuMeavhTaKPFuk3OXW9LrcEP75Ao9z0M+4UqpiaR+mXEJPWarKtgwYKyKNAUSkkYi0xP5ZHOsocyew1hhzBjgtIoMc2ycBq4wxqUCCiPzOsQ8fEfGt1FYopdyV9mHKJTR5q0pljNklIs8Ai0XEBlwAHgbOAp1EZBNwBvs1GgBTgJmOzioOuNuxfRIwS0Sed+zj9kpshlLKTWkfplxFjLncqKpSlUNE0o0xda2uh1JKlYX2Yaq89JSlUkoppZTFdIRMKaWUUspiOkKmlFJKKWUxDWRKKaWUUhbTQKaUUkopZTENZEoppZRSFtNAppRSSillsf8Hjrj8EkqpQSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### my_model2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "fig.subplots_adjust(hspace = 2)\n",
    "\n",
    "x = [ (i+1)/32 for i in range(64)]\n",
    "\n",
    "#valid_loss2 = [ i*500 for i in valid_loss]\n",
    "ax1.plot(x, train_loss, label = 'train loss')\n",
    "#ax1.plot(x, valid_loss2, label = 'valid loss')\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"loss\")\n",
    "ax1.legend()\n",
    "#ax1.title(\"Losses over epochs\")\n",
    "\n",
    "\n",
    "ax2.plot(x, train_acc, c = 'blue', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "\n",
    "#ax2.plot(x, valid_acc, c = 'red', label = 'validation accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [links for initial state]\n",
    "- https://stackoverflow.com/questions/38441589/is-rnn-initial-state-reset-for-subsequent-mini-batches/41239965\n",
    "- https://www.programcreek.com/python/example/102774/tensorflow.contrib.rnn.LSTMStateTuple\n",
    "- https://github.com/tensorflow/tensorflow/issues/3476\n",
    "\n",
    "### 전체적인 구조\n",
    "- http://www.hanbit.co.kr/media/channel/view.html?cms_code=CMS6074576268\n",
    "- [Introduction to Recurrent Networks in Tensorflow]('https://danijar.com/introduction-to-recurrent-networks-in-tensorflow/')\n",
    "- <font color = 'red'>[RNN Tutorial Part 4 - GRU/LSTM RNN 구조를 Python과 Theano를 이용하여 구현하기]('https://aikorea.org/blog/rnn-tutorial-4/')</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_71:0' shape=(1, 2, 3) dtype=int32_ref>\n",
      "Tensor(\"stack_7:0\", shape=(1, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([[[1,2,3],[4,5,6]]])\n",
    "print(a)\n",
    "a = tf.unstack(a, axis=1)\n",
    "a = tf.stack(a, axis=1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "You can test your model in train, validation samples with sample images.<br>\n",
    "Final evaluation will be done with average BLEU score.<br>\n",
    "BLEU (bilingual evaluation understudy) score is between 0 and 1. The values closer to 1 represents more similar texts. <br>\n",
    "https://en.wikipedia.org/wiki/BLEU\n",
    "<font color=red>**Your model could be evaluated without traning procedure,**</font> if you saved and loaded your model properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "from coco_utils import *\n",
    "from captioning import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "model_path='./models_captioning'\n",
    "data_path ='./coco/coco_captioning'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_data = load_coco_data()\n",
    "\n",
    "captions = train_data['train_captions']\n",
    "img_idx  = train_data['train_image_idxs']\n",
    "img_features = train_data['features'][img_idx]\n",
    "word_to_idx = train_data['word_to_idx']\n",
    "idx_to_word = train_data['idx_to_word']\n",
    "vcaptions = train_data['val_captions']\n",
    "vimg_idx  = train_data['val_image_idxs']\n",
    "vimg_features = train_data['features'][vimg_idx]\n",
    "\n",
    "n_words = len(word_to_idx)\n",
    "maxlen = train_data['train_captions'].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for image captioning predicting\n",
    "# The image_captioning should include following functions\n",
    "# - load your saved model \n",
    "# - return predicted captions from image features\n",
    "\n",
    "def image_captioning(features) :\n",
    "    pr_captions = np.zeros((features.shape[0],maxlen),int)\n",
    "    #################################################\n",
    "    # TODO: Implement predicting image captioning\n",
    "    # - load your saved model\n",
    "    # - predict the captions\n",
    "    #################################################\n",
    "    \n",
    "    #################################################\n",
    "    #                END OF YOUR CODE               #\n",
    "    #################################################\n",
    "    return pr_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    minibatch = sample_coco_minibatch(train_data, split=split, batch_size=1)\n",
    "\n",
    "    gt_captions, features, urls = minibatch\n",
    "    pr_captions = image_captioning(features)\n",
    "\n",
    "    show_predict_samples(gt_captions, pr_captions, urls, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints unigram BLEU score averaged over val dataset\n",
    "\n",
    "def evaluate_model(data, split):\n",
    "    BLEUscores = {}\n",
    "\n",
    "    minibatch = sample_coco_minibatch(data, split=split, batch_size=\"All\")\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    pr_captions = image_captioning(features)\n",
    "    pr_captions = decode_captions(pr_captions, data['idx_to_word'])\n",
    "\n",
    "    total_score = 0.0\n",
    "        \n",
    "    for gt_caption, pr_caption, url in zip(gt_captions, pr_captions, urls):\n",
    "        total_score += BLEU_score(gt_caption, pr_caption)\n",
    "\n",
    "    BLEUscores[split] = total_score / len(pr_captions)\n",
    "\n",
    "    for split in BLEUscores:\n",
    "        print('Average BLEU score for %s: %f' % (split, BLEUscores[split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(train_data,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for TA, TA will evaluate your model with independent test_data\n",
    "# the number of captions of test_data is about 200,000\n",
    "# you should handle captions up to 200,000\n",
    "\n",
    "#evaluate_model(test_data,'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you did here\n",
    "In this cell you should also write an explanation of what you did.<br>\n",
    "(A detailed description of your model, structure, tensorflow module and others)\n",
    "<font color=red>**You must describe your model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tell us here_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
